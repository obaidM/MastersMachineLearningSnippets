{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA on project 1 model and comparing the answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 45)\n",
      "the new dimensions are: (776, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df1 = pd.read_csv(\"audit_risk.csv\")\n",
    "df2 = pd.read_csv(\"trial.csv\")\n",
    "\n",
    "### combine the two files in one dataframe\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "print(df.shape)\n",
    "\n",
    "## remove duplicate columns \n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "print(\"the new dimensions are:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove Para A , score A, para B, score B , number , score B1 , money value , score_MV ,prob\n",
    "## history ,loss\n",
    "df =  df.drop(['para_a','score_a','para_b','score_b','numbers','score_b.1',\n",
    "               'money_value','score_mv','prob','history','loss','total','marks','district','district_loss'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['location_id'] !='LOHARU')]\n",
    "df = df[(df['location_id'] !='NUH')]\n",
    "df = df[(df['location_id'] !='SAFIDON')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.get_dummies(df['location_id'],columns='location_id',prefix='location_id')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('location_id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define y & X for Regression and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "y= df['audit_risk']\n",
    "X = df.drop(['audit_risk','risk'],axis =1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together \n",
    "X_test = scaler.transform(x_test_org)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "(pca.n_components_)\n",
    "# obviously Y_train and Y_test will remain the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LINEAR REGRESSION WITH SCALED DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rsquare for the training score  0.7332681958939451\n",
      " R square for the testing score 0.4154294556445164\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lreg = LinearRegression()\n",
    "lreg.fit(X_train_reduced,y_train)\n",
    "print(\" Rsquare for the training score \",lreg.score(X_train_reduced,y_train))  \n",
    "print(\" R square for the testing score\",lreg.score(X_test_reduced,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1\n",
    "\n",
    "Rsquare for the training score  0.7830502165730896\n",
    " R square for the testing score -1.643814292771407e+20\n",
    "\n",
    "PCA has increased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7332681958668796, 0.7332681931879641, 0.7332679258629285, 0.7332417468031724]\n",
      "[0.4154277611631818, 0.41541251233998255, 0.41526017317973907, 0.4137513956837684]\n",
      "7.746013818703005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "x_range =[0.01,0.1,1,10]  ## my alpha values\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for alpha in x_range:\n",
    "    ridge = Ridge(alpha)\n",
    "    ridge.fit(X_train_reduced,y_train)  ## takes in transformed data\n",
    "    train_score_list.append(ridge.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(ridge.score(X_test_reduced,y_test))\n",
    "    \n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "\n",
    "myMSE =   mean_absolute_error(y_test, ridge.predict(X_test_reduced))  \n",
    "print(myMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1\n",
    "\n",
    "[0.7829860706971614, 0.7829860369295791, 0.7829827098442731, 0.7826937138639045]\n",
    "\n",
    "[0.3866234682134856, 0.38661045435609454, 0.38648192513470336, 0.38533008111218126]\n",
    "7.760384024706278\n",
    "\n",
    "PCA has increased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION WITH LASSO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7332561121601334, 0.73232206695603, 0.7096104603854185, 0.5534616429663237]\n",
      "[0.4150203409790395, 0.41147703970127303, 0.37819466373845134, 0.28517502098734393]\n",
      "[7.763804110862891, 7.683152408134549, 7.616127360646484, 8.159283572306089]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "x_range =[0.01,0.1,1,10]  ## my alpha values\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror = []\n",
    "\n",
    "for alpha in x_range:\n",
    "    lasso = Lasso(alpha)\n",
    "    lasso.fit(X_train_reduced,y_train)  ## takes in transformed data\n",
    "    train_score_list.append(lasso.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(lasso.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, lasso.predict(X_test_reduced))  )\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1 \n",
    "\n",
    "[0.7829609433309788, 0.7812646453482364, 0.7632022772958634, 0.2708999232944497]\n",
    "\n",
    "[0.38414227031223036, 0.3769460513628495, 0.37920019126687576, 0.14264531754350085]\n",
    "\n",
    "[7.837493045213592, 7.623604925354731, 6.776201976242107, 10.780088896259842]\n",
    "\n",
    "PCA has increased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KNN REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.7800149299254359, 0.6706641315958126, 0.5021239101036725]\n",
      "[0.24953770067710568, 0.14099478355375306, 0.19567389910633382, 0.14452871011443613]\n",
      "[6.799036536082474, 7.201993587628866, 7.276881232989691, 7.997664377319588]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "x_range = [1,5,10,20]\n",
    "train_score_list = []  ## initialize array to hold train values\n",
    "test_score_list = []  ## initilaize array to hold test values\n",
    "meanerror = []\n",
    "for k in x_range:\n",
    "    knn = KNeighborsRegressor(k)\n",
    "    knn.fit(X_train_reduced,y_train)\n",
    "    train_score_list.append(knn.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(knn.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, knn.predict(X_test_reduced))  )\n",
    "    \n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From project 1 \n",
    "\n",
    "[1.0, 0.7609770762651131, 0.6748953837754075, 0.5017213680846089]\n",
    "\n",
    "[0.13327111121285895, 0.13823029974669154, 0.11544032272264104, 0.11591615746873318]\n",
    "\n",
    "[7.421704288659794, 7.254362787628864, 7.71078089484536, 7.98531694329897]\n",
    "\n",
    "PCA has increased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  POLYNOMIAL FEATURES REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7332556685247846, 1.0, 1.0]\n",
      "[0.41543988379120633, 0.9577962654910536, 0.22873033821376465]\n",
      "[7.777503358247423, 3.8421806064265613, 9.599189580492368]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror = []\n",
    "for n in range (1,4):\n",
    "    poly = PolynomialFeatures(n)\n",
    "    X_train_poly = poly.fit_transform(X_train_reduced)\n",
    "    X_test_poly = poly.transform(X_test_reduced)\n",
    "    lreg.fit(X_train_poly,y_train)\n",
    "    train_score_list.append(lreg.score(X_train_poly,y_train))\n",
    "    test_score_list.append(lreg.score(X_test_poly,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, lreg.predict(X_test_poly))  )\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Project 1\n",
    "\n",
    "[0.7828426062704892, 1.0, 1.0]\n",
    "\n",
    "[-1.7470218133600505e+20, 0.9878348575181182, -0.2707410564322985]\n",
    "\n",
    "[66898111964.04364, 1.3660816068369177, 7.573433502061889]\n",
    "\n",
    "PCA performance dropped. Best testing Score was 98% in project 1 but is 95% in Project2. However the drop is not that significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SUPPORT VECTOR REGRESSION -- SIMPLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9733176511371148, 0.9999755804552232, 0.9999791279739522, 0.9999791279739522]\n",
      "[0.05718868181851633, 0.05981613030066857, 0.06021439819775909, 0.06021439819775909]\n",
      "[7.29520644373952, 7.21445362405136, 7.210161806462873, 7.210161806462873]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR \n",
    "\n",
    "clist = [100,1000,10000,20000]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror = []\n",
    "\n",
    "for c in clist:\n",
    "    svr_linear  = SVR(gamma='scale', C= c)\n",
    "    svr_linear.fit(X_train_reduced, y_train) \n",
    "    train_score_list.append(svr_linear.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(svr_linear.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, svr_linear.predict(X_test_reduced)  ))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From project 1 \n",
    "\n",
    "[0.9618397945808, 0.9999801118503574, 0.9999801118503574, 0.9999801118503574]\n",
    "\n",
    "[0.05655963125766061, 0.06052379486293036, 0.06052379486293036, 0.06052379486293036]\n",
    "\n",
    "[7.262944255807923, 7.19535155365798, 7.19535155365798, 7.19535155365798]\n",
    "\n",
    "PCA didn't affect much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SUPPORT VECTOR REGRESSION --  KERNEL = 'LINEAR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6256882441710763, 0.5890253697274963, 0.5892196221527297]\n",
      "[0.28986790416987573, 0.2860901550377981, 0.28614546307546773]\n",
      "[6.811897583952913, 6.721623756344239, 6.72139233758531]\n"
     ]
    }
   ],
   "source": [
    "### do regression with linear kernal \n",
    "clist = [1,100,1000]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror = []\n",
    "\n",
    "for c in clist:\n",
    "    svr_linear  = SVR(kernel='linear', C= c)\n",
    "    svr_linear.fit(X_train_reduced, y_train) \n",
    "    train_score_list.append(svr_linear.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(svr_linear.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, svr_linear.predict(X_test_reduced)  ))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From project 1 \n",
    "\n",
    "[0.6750680838516158, 0.6874199730620176, 0.687412544813394]\n",
    "\n",
    "[0.3692705233663382, 0.3755440215142677, 0.37541162718068666]\n",
    "\n",
    "[5.60233540029695, 5.6443355332645515, 5.644447331435919]\n",
    "\n",
    "PCA decreased performace with this model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SUPPORT VECTOR with KERNEL = 'poly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7153255610163917, 0.997072841545629, 0.9998486269477955]\n",
      "[-3.234242622333264, -30.083213697109368, -16.157635881101783]\n",
      "[13.036988610034328, 32.43741605500168, 26.432258944026074]\n"
     ]
    }
   ],
   "source": [
    "### do regression with kernel = 'poly'\n",
    "clist = [1,100,1000]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror = []\n",
    "\n",
    "for c in clist:\n",
    "    svr_poly  = SVR(kernel='poly', C= c)\n",
    "    svr_poly.fit(X_train_reduced , y_train) \n",
    "    train_score_list.append(svr_poly.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(svr_poly.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, svr_poly.predict(X_test_reduced)  ))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1\n",
    "\n",
    "[0.5902799601576962, 0.9987973929478173, 0.9999764111932848]\n",
    "\n",
    "[-3.508972636413392, -17.655690989286125, -6.365209764884323]\n",
    "\n",
    "[13.67803333853138, 25.17642268667497, 17.359873702866285]\n",
    "\n",
    "PCA dropped performance. But this model overall suffers from overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  SUPPORT VECTOR REGRESSION --  KERNEL = 'RBF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9999791098656481, 0.9999791956345712, 0.9999791956345712]\n",
      "[0.043475369310652545, 0.0434810410283214, 0.0434810410283214]\n",
      "[8.374337513023077, 8.373880988472035, 8.373880988472035]\n"
     ]
    }
   ],
   "source": [
    "### do regression with kernel = 'rbf'\n",
    "clist = [1000,10000,100000]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "meanerror= []\n",
    "\n",
    "for c in clist:\n",
    "    svr_k  = SVR(kernel='rbf',gamma=0.1, C= c)\n",
    "    svr_k.fit(X_train_reduced, y_train) \n",
    "    train_score_list.append(svr_k.score(X_train_reduced,y_train))\n",
    "    test_score_list.append(svr_k.score(X_test_reduced,y_test))\n",
    "    meanerror.append(mean_absolute_error(y_test, svr_k.predict(X_test_reduced)  ))\n",
    "    \n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)\n",
    "print(meanerror)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1\n",
    "\n",
    "[0.9999771645052283, 0.9999771645052283, 0.9999771645052283]\n",
    "\n",
    "[0.040596482407019185, 0.040596482407019185, 0.040596482407019185]\n",
    "\n",
    "[8.74927233213569, 8.74927233213569, 8.74927233213569]\n",
    "\n",
    "PCA didn't change much. Models suffers greatly from overfitting and doesnot generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data Ready for classification, scale it and split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## For classification things will be different \n",
    "y= df['risk']\n",
    "X = df.drop(['audit_risk','risk'],axis =1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together \n",
    "X_test = scaler.transform(x_test_org)  \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "(pca.n_components_)\n",
    "# obviously Y_train and Y_test will remain the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores are:   [1.0, 0.948, 0.952, 0.919, 0.919, 0.895, 0.907, 0.891, 0.898]\n",
      "test scores are:  [0.907, 0.866, 0.881, 0.84, 0.861, 0.835, 0.851, 0.84, 0.84]\n"
     ]
    }
   ],
   "source": [
    "## KNN classification \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "for k in range(1,10):\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train_reduced,y_train)\n",
    "    train_score_list.append( round(knn.score(X_train_reduced,y_train),3))\n",
    "    test_score_list.append(  round(knn.score(X_test_reduced,y_test),3))\n",
    "\n",
    "print(\"train scores are:  \", train_score_list)\n",
    "print(\"test scores are: \",test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRom Project 1\n",
    "\n",
    "train scores are:   [1.0, 0.936, 0.95, 0.907, 0.914, 0.881, 0.896, 0.879, 0.888]\n",
    "    \n",
    "test scores are:  [0.881, 0.845, 0.851, 0.83, 0.84, 0.82, 0.84, 0.804, 0.799]\n",
    "    \n",
    "PCA increased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CLASSIFICATION WITH LOGISTIC REGRESSION WITH C  clist = [0.01,0.1,1,10,100]  penality = 'l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores are:   [0.921, 0.945, 0.991, 0.993, 0.995]\n",
      "test scores are:  [0.892, 0.943, 0.974, 0.948, 0.938]\n"
     ]
    }
   ],
   "source": [
    "## logistic regression \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clist = [0.01,0.1,1,10,100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "\n",
    "for c in clist:\n",
    "    log_l1 = LogisticRegression(penalty='l1', C=c )\n",
    "    log_l1.fit(X_train_reduced,y_train)\n",
    "    train_score_list.append( round(log_l1.score(X_train_reduced,y_train),3))\n",
    "    test_score_list.append( round(log_l1.score(X_test_reduced,y_test),3))\n",
    "\n",
    "print(\"train scores are:  \", train_score_list)\n",
    "print(\"test scores are: \",test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1\n",
    "\n",
    "train scores are:   [0.888, 0.976, 0.986, 0.998, 1.0]\n",
    "    \n",
    "test scores are:  [0.871, 0.959, 0.979, 0.974, 0.964]\n",
    "    \n",
    "    PCA had little effect but no impact overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Classification with LOGISTIC REGRESSION WITH PENALITY ='L2' &  clist = [0.01,0.1,1,10,100]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores are:   [0.922, 0.952, 0.99, 0.993, 0.993]\n",
      "test scores are:  [0.902, 0.948, 0.959, 0.954, 0.954]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clist = [0.01,0.1,1,10,100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "\n",
    "for c in clist:\n",
    "    log_l2 = LogisticRegression(penalty='l2', C=c, solver='lbfgs')\n",
    "    log_l2.fit(X_train_reduced,y_train)\n",
    "    train_score_list.append(  round(log_l2.score(X_train_reduced,y_train),3))\n",
    "    test_score_list.append(   round(log_l2.score(X_test_reduced,y_test),3))\n",
    "\n",
    "print(\"train scores are:  \", train_score_list)\n",
    "print(\"test scores are: \",test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1 \n",
    "\n",
    "train scores are:   [0.938, 0.976, 0.988, 0.991, 0.998]\n",
    "\n",
    "test scores are:  [0.923, 0.959, 0.974, 0.969, 0.974]\n",
    "    \n",
    "PCA has very little effect.It has slightly decreased the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATIONS with SVC  SIMPLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.993\n",
      "testing score is 0.954\n",
      " coefficents are  (1, 44)\n",
      "intercepts are (1,)\n"
     ]
    }
   ],
   "source": [
    "### SVM simple \n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC().fit(X_train_reduced,y_train)\n",
    "print(\"training score is {:.3f}\".format(linear_svm.score(X_train_reduced,y_train)))\n",
    "print(\"testing score is {:.3f}\".format( linear_svm.score(X_test_reduced,y_test)))\n",
    "\n",
    "print(\" coefficents are \",linear_svm.coef_.shape)\n",
    "print(\"intercepts are\",linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1 \n",
    "\n",
    "training score is 0.995\n",
    "\n",
    "testing score is 0.995\n",
    "\n",
    " coefficents are  (1, 56)\n",
    " \n",
    "intercepts are (1,)\n",
    "\n",
    "PCA made accuracy worse. Drop of 4 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  CLASSIFICATION WITH SVC with KERNAL = 'LINEAR'   & C = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.991\n",
      "testing score is 0.948\n"
     ]
    }
   ],
   "source": [
    "### with kernel trick linear kernel \n",
    "\n",
    "from  sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C= 1.0)\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"training score is {:.3f}\".format(clf.score(X_train_reduced,y_train)))\n",
    "print(\"testing score is {:.3f}\".format(clf.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Project 1 \n",
    "\n",
    "training score is 0.995\n",
    "testing score is 0.995\n",
    "\n",
    "PCA decreased performance liitle bit. by 5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION WITH SVC with KERNAL='LINEAR' & C = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.988\n",
      "testing score is 0.943\n"
     ]
    }
   ],
   "source": [
    "### with kernel trick linear kernel \n",
    "\n",
    "from  sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear', C= 10)\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"training score is {:.3f}\".format(clf.score(X_train_reduced,y_train)))\n",
    "print(\"testing score is {:.3f}\".format( clf.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1:\n",
    "    \n",
    "training score is 0.995\n",
    "\n",
    "testing score is 0.995\n",
    "\n",
    "PCA dropped the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION WITH SVC with KERNAL = 'RBF' , C =1.0 , GAMMA  = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.991\n",
      "testing score is 0.907\n"
     ]
    }
   ],
   "source": [
    "### with kernel trick with rbf  \n",
    "\n",
    "from  sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf', C= 1.0 , gamma = 0.7)\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"training score is {:.3f}\".format(clf.score(X_train_reduced,y_train)))\n",
    "print(\"testing score is {:.3f}\".format(clf.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1:\n",
    "    \n",
    "training score is 1.000\n",
    "\n",
    "testing score is 0.959\n",
    "\n",
    "PCA has dropped the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION WITH SVC with KERNAL = 'POLY' & Degree = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is 0.850\n",
      "testing score is 0.778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "### with kernel trick with polynomial and degree is 3 \n",
    "\n",
    "from  sklearn.svm import SVC\n",
    "clf = SVC(kernel='poly', C= 1.0 , degree = 3)\n",
    "clf.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"training score is {:.3f}\".format(clf.score(X_train_reduced,y_train)))\n",
    "print(\"testing score is {:.3f}\".format(clf.score(X_test_reduced,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1:\n",
    "    \n",
    "training score is 0.965\n",
    "\n",
    "testing score is 0.964\n",
    "\n",
    "PCA has dropped the accuracy significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION WITH DECISION TREE WITH MAX PATH =4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is  0.9930915371329879\n",
      "testing score is 0.9226804123711341\n"
     ]
    }
   ],
   "source": [
    "### deceison tree with max depth 4\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier( max_depth=4 ,random_state=0)\n",
    "\n",
    "dtree.fit(X_train_reduced,y_train)\n",
    "\n",
    "print(\"training score is \",dtree.score(X_train_reduced,y_train))\n",
    "print(\"testing score is\", dtree.score(X_test_reduced,y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project 1:\n",
    "    \n",
    "training score is  1.0\n",
    "\n",
    "testing score is 0.9948453608247423\n",
    "\n",
    "PCA dropped the accuracy by 7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  PCA improved performance slightly in regression  but PCA dropped performace slightly ( between 3%-8%) for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
