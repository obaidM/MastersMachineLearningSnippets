{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Tasks\n",
    "- In the dataframe creates in Lab 2 - Part a set ``Salary`` as the target value. \n",
    "- The rest of the columns are considered as X, feature set. \n",
    "- Use ``train_test_split`` to split the dataset into train and test dataset. set ``random_state = 0``.\n",
    "- Use ``MinMaxScaler`` to scale feature set X. \n",
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data != ' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['workclass', 'education', 'occupation', 'native-country']\n",
    "data.drop(l, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['marital-status'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('marital-status', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['relationship'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('relationship', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['race'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('race', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex'] = data['sex'].map({' Male':0, ' Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Salary'] = data['Salary'].map({' <=50K':0, ' >50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Salary']\n",
    "X = data.drop(['Salary'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 25)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together\n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets do PCA ### It is done after preprocessing and split of data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Use PCA is to reduce the size of the feature space while retaining 95% of explained variance. What is the size of the transformed feature space? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24420, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### X is reduced from this point onwards \n",
    "print(X_train.shape)\n",
    "(pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "For the rest of this lab, we will consider reduced train and test sets. For models with hyper-parameter ``random_state = 0``. \n",
    "\n",
    "Use grid search to find the best parameters of a support vector machine with kernel ``'rbf'`` and following range of parameters: \n",
    "```Python\n",
    "C in [0.1, 1, 10]\n",
    "gamma in [0.1, 1, 10]\n",
    "cv = 5```\n",
    "\n",
    "What are the best parameters of this model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters are:{'C': 10, 'gamma': 10, 'kernel': 'rbf', 'random_state': 0}\n",
      "best accuracy score: 0.827\n"
     ]
    }
   ],
   "source": [
    "# lets build a SVM kernel rbf model  and then we will feed it to gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from  sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\n",
    "param_grid = { 'C':[0.1,1,10],\n",
    "             'gamma':[0.1,1,10],\n",
    "             'kernel': ['rbf'],\n",
    "             'random_state' :[0]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),param_grid, cv=5 )\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(\"best paramaters are:{}\".format(grid_search.best_params_))\n",
    "print(\"best accuracy score: {:.3f}\".format(grid_search.best_score_))\n",
    "\n",
    "### elearning is giving the answer C = 10 gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Train a gradient boosting machine learning model on this dataset with the following hyper-parameters. \n",
    "```Python\n",
    "n_estimators= 100\n",
    "learning_rate=0.5\n",
    "random_state = 0\n",
    "```\n",
    "\n",
    "What is the auc score of test set? (2 significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.863\n",
      "Accuracy on testing  set: 0.820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350312989006923"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0, n_estimators = 100, learning_rate =0.5)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "pred = gbrt.predict(X_test)\n",
    "pred = pd.Series(pred)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on testing  set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8141,)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Using the model created for previous questions, call ``predict_proba`` on the test set. Now change the threshold from 0.5 to 0.75, which means if the probability of an instance belongs to class 0 is higher than or equal to 0.75, then the prediction is label 0, otherwise is label 1. \n",
    "\n",
    "Now, what is the auc score of test dataset? (2 significant digits)\n",
    "\n",
    "**Note:** The first index of ``predict_proba`` refers to the probability that the data belong to class 0, and the second refers to the probability that the data belong to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.75\n",
    "pred_df = pd.DataFrame( gbrt.predict_proba(X_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pred'] =  pred_df[1].apply(lambda x: 1 if  x>=thresh else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6231268951002275"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_df['pred'])\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975435</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824839</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973031</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664415</td>\n",
       "      <td>0.335585</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.686872</td>\n",
       "      <td>0.313128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.978877</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.964385</td>\n",
       "      <td>0.035615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.419016</td>\n",
       "      <td>0.580984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.993520</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.990373</td>\n",
       "      <td>0.009627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.876891</td>\n",
       "      <td>0.123109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.857664</td>\n",
       "      <td>0.142336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.704663</td>\n",
       "      <td>0.295337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.713714</td>\n",
       "      <td>0.286286</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.403473</td>\n",
       "      <td>0.596527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.901501</td>\n",
       "      <td>0.098499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.959896</td>\n",
       "      <td>0.040104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.982229</td>\n",
       "      <td>0.017771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.569934</td>\n",
       "      <td>0.430066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.208539</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.293883</td>\n",
       "      <td>0.706117</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.469450</td>\n",
       "      <td>0.530550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.982395</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.993520</td>\n",
       "      <td>0.006480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.972836</td>\n",
       "      <td>0.027164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.976460</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.993011</td>\n",
       "      <td>0.006989</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.978565</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8108</th>\n",
       "      <td>0.965453</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8110</th>\n",
       "      <td>0.418587</td>\n",
       "      <td>0.581413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8111</th>\n",
       "      <td>0.977075</td>\n",
       "      <td>0.022925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8113</th>\n",
       "      <td>0.959457</td>\n",
       "      <td>0.040543</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>0.987800</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8115</th>\n",
       "      <td>0.982889</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>0.921212</td>\n",
       "      <td>0.078788</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>0.991181</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8119</th>\n",
       "      <td>0.822996</td>\n",
       "      <td>0.177004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8120</th>\n",
       "      <td>0.959707</td>\n",
       "      <td>0.040293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8121</th>\n",
       "      <td>0.993270</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8122</th>\n",
       "      <td>0.286108</td>\n",
       "      <td>0.713892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>0.991633</td>\n",
       "      <td>0.008367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>0.495481</td>\n",
       "      <td>0.504519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>0.989090</td>\n",
       "      <td>0.010910</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>0.987113</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>0.983023</td>\n",
       "      <td>0.016977</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8128</th>\n",
       "      <td>0.768813</td>\n",
       "      <td>0.231187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8129</th>\n",
       "      <td>0.539275</td>\n",
       "      <td>0.460725</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8130</th>\n",
       "      <td>0.441840</td>\n",
       "      <td>0.558160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>0.986652</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>0.986240</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>0.992218</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>0.889084</td>\n",
       "      <td>0.110916</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>0.997501</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>0.991077</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>0.776577</td>\n",
       "      <td>0.223423</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>0.887307</td>\n",
       "      <td>0.112693</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.501241</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>0.956700</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7415 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1  pred\n",
       "0     0.983631  0.016369     0\n",
       "1     0.975435  0.024565     0\n",
       "2     0.824839  0.175161     0\n",
       "3     0.973031  0.026969     0\n",
       "4     0.664415  0.335585     0\n",
       "5     0.686872  0.313128     0\n",
       "6     0.978877  0.021123     0\n",
       "7     0.964385  0.035615     0\n",
       "8     0.419016  0.580984     0\n",
       "9     0.993520  0.006480     0\n",
       "10    0.990373  0.009627     0\n",
       "11    0.876891  0.123109     0\n",
       "13    0.857664  0.142336     0\n",
       "14    0.704663  0.295337     0\n",
       "15    0.713714  0.286286     0\n",
       "16    0.403473  0.596527     0\n",
       "18    0.901501  0.098499     0\n",
       "19    0.959896  0.040104     0\n",
       "20    0.982229  0.017771     0\n",
       "21    0.569934  0.430066     0\n",
       "22    0.791461  0.208539     0\n",
       "23    0.969529  0.030471     0\n",
       "25    0.293883  0.706117     0\n",
       "26    0.469450  0.530550     0\n",
       "27    0.982395  0.017605     0\n",
       "28    0.993520  0.006480     0\n",
       "29    0.972836  0.027164     0\n",
       "30    0.976460  0.023540     0\n",
       "31    0.993011  0.006989     0\n",
       "32    0.978565  0.021435     0\n",
       "...        ...       ...   ...\n",
       "8108  0.965453  0.034547     0\n",
       "8110  0.418587  0.581413     0\n",
       "8111  0.977075  0.022925     0\n",
       "8113  0.959457  0.040543     0\n",
       "8114  0.987800  0.012200     0\n",
       "8115  0.982889  0.017111     0\n",
       "8117  0.921212  0.078788     0\n",
       "8118  0.991181  0.008819     0\n",
       "8119  0.822996  0.177004     0\n",
       "8120  0.959707  0.040293     0\n",
       "8121  0.993270  0.006730     0\n",
       "8122  0.286108  0.713892     0\n",
       "8123  0.991633  0.008367     0\n",
       "8124  0.495481  0.504519     0\n",
       "8125  0.989090  0.010910     0\n",
       "8126  0.987113  0.012887     0\n",
       "8127  0.983023  0.016977     0\n",
       "8128  0.768813  0.231187     0\n",
       "8129  0.539275  0.460725     0\n",
       "8130  0.441840  0.558160     0\n",
       "8131  0.986652  0.013348     0\n",
       "8132  0.986240  0.013760     0\n",
       "8133  0.992218  0.007782     0\n",
       "8134  0.889084  0.110916     0\n",
       "8135  0.997501  0.002499     0\n",
       "8136  0.991077  0.008923     0\n",
       "8137  0.776577  0.223423     0\n",
       "8138  0.887307  0.112693     0\n",
       "8139  0.498759  0.501241     0\n",
       "8140  0.956700  0.043300     0\n",
       "\n",
       "[7415 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df[(pred_df['pred'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
