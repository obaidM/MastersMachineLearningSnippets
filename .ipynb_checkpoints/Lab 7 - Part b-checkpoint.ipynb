{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Tasks\n",
    "- Use the following data prepration steps. \n",
    "- Use ``train_test_split`` to split the dataset into train and test dataset. set ``random_state = 0``.\n",
    "- Use ``StandardScaler`` to scale feature set X. \n",
    "- In this lab use ``random_state = 0`` whenever is aplicable. \n",
    "\n",
    "### Data prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('auto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "data = data[data != '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['horsepower'] = data['horsepower'].astype(float)\n",
    "df = data[['cylinders', 'horsepower']]\n",
    "g = df.groupby('cylinders').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_imputed = df.apply(lambda grp: grp.fillna(grp.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['horsepower'] = data_imputed['horsepower'].astype(float)\n",
    "data.drop(['car name'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['mpg']\n",
    "X = data.drop(['mpg'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together\n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Use the ``LocallyLinearEmbedding`` to reduce the dimensionality of this dataset to 4 (``random_state = 0``). Train a polynomial regression of degree 2 on the reduced dataset. What is the test score of this model? (2 significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score is: 0.6820011447611809\n",
      "test score is: 0.6351372701269989\n"
     ]
    }
   ],
   "source": [
    "random_state = 0\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "\n",
    "lle = LocallyLinearEmbedding(n_components=4,  random_state=0)\n",
    "\n",
    "X_train = lle.fit_transform(X_train)\n",
    "\n",
    "X_test = lle.transform(X_test)\n",
    "#####  transform to polynomial features\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "n=2   ## we are using 2 degress, usually 2 or 3 are enough for polynomial features \n",
    "poly = PolynomialFeatures(n)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "### perform linear regression on the polynomial features \n",
    "from sklearn.linear_model import LinearRegression\n",
    "lreg = LinearRegression()\n",
    "\n",
    "lreg.fit(X_train_poly,y_train)\n",
    "print(\"train score is:\",lreg.score(X_train_poly,y_train))\n",
    "print(\"test score is:\",lreg.score(X_test_poly,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocallyLinearEmbedding(eigen_solver='auto', hessian_tol=0.0001, max_iter=100,\n",
       "            method='standard', modified_tol=1e-12, n_components=4,\n",
       "            n_jobs=None, n_neighbors=5, neighbors_algorithm='auto',\n",
       "            random_state=0, reg=0.001, tol=1e-06)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "Use the ``LocallyLinearEmbedding`` to reduce the dimensionality of this dataset to 4 (``random_state = 0``). Train a support vector machine with kernel ``poly`` on the reduced dataset with the following parameters: \n",
    "```Python\n",
    "gamma = 0.1 \n",
    "C = 1\n",
    "epsilon=0.5\n",
    "```\n",
    "What is the mean squared error of the reduced train set? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1, cache_size=200, coef0=0.0, degree=3, epsilon=0.5, gamma=0.1,\n",
       "  kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR \n",
    "svr_poly  = SVR(gamma=0.1, C= 1,epsilon=0.5, kernel='poly')\n",
    "svr_poly.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.13569442482527"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "mean_squared_error(y_train, svr_poly.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
