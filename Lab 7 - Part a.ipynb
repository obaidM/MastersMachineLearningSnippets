{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Tasks\n",
    "- In the dataframe creates in Lab 2 - Part a set ``Salary`` as the target value. \n",
    "- The rest of the columns are considered as X, feature set. \n",
    "- Use ``train_test_split`` to split the dataset into train and test dataset. set ``random_state = 0``.\n",
    "- Use ``MinMaxScaler`` to scale feature set X. \n",
    "\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\pandas\\core\\ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "data = data[data != ' ?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['workclass', 'education', 'occupation', 'native-country']\n",
    "data.drop(l, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['marital-status'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('marital-status', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['relationship'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('relationship', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(data['race'])\n",
    "data = pd.concat([data, df], axis = 1)\n",
    "data.drop('race', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sex'] = data['sex'].map({' Male':0, ' Female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Salary'] = data['Salary'].map({' <=50K':0, ' >50K':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Salary']\n",
    "X = data.drop(['Salary'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype uint8, int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together\n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets do PCA ### It is done after preprocessing and split of data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 1\n",
    "Use PCA is to reduce the size of the feature space while retaining 95% of explained variance. What is the size of the transformed feature space? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24420, 12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### X is reduced from this point onwards \n",
    "print(X_train.shape)\n",
    "(pca.n_components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "For the rest of this lab, we will consider reduced train and test sets. For models with hyper-parameter ``random_state = 0``. \n",
    "\n",
    "Use grid search to find the best parameters of a support vector machine with kernel ``'rbf'`` and following range of parameters: \n",
    "```Python\n",
    "C in [0.1, 1, 10]\n",
    "gamma in [0.1, 1, 10]\n",
    "cv = 5```\n",
    "\n",
    "What are the best parameters of this model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best paramaters are:{'C': 10, 'gamma': 10, 'kernel': 'rbf', 'random_state': 0}\n",
      "best accuracy score: 0.827\n"
     ]
    }
   ],
   "source": [
    "# lets build a SVM kernel rbf model  and then we will feed it to gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from  sklearn.svm import SVC\n",
    "\n",
    "param_grid = { 'C':[0.1,1,10],\n",
    "             'gamma':[0.1,1,10],\n",
    "             'kernel': ['rbf'],\n",
    "             'random_state' :[0]}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),param_grid, cv=5 )\n",
    "\n",
    "grid_search.fit(X_train,y_train)\n",
    "\n",
    "print(\"best paramaters are:{}\".format(grid_search.best_params_))\n",
    "print(\"best accuracy score: {:.3f}\".format(grid_search.best_score_))\n",
    "\n",
    "### elearning is giving the answer C = 10 gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=10, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "Train a gradient boosting machine learning model on this dataset with the following hyper-parameters. \n",
    "```Python\n",
    "n_estimators= 100\n",
    "learning_rate=0.5\n",
    "random_state = 0\n",
    "```\n",
    "\n",
    "What is the auc score of test set? (2 significant digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.863\n",
      "Accuracy on testing  set: 0.820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350312989006923"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbrt = GradientBoostingClassifier(random_state=0, n_estimators = 100, learning_rate =0.5)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "pred = gbrt.predict(X_test)\n",
    "pred = pd.Series(pred)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbrt.score(X_train, y_train)))\n",
    "print(\"Accuracy on testing  set: {:.3f}\".format(gbrt.score(X_test, y_test)))\n",
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8141,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 4\n",
    "\n",
    "Using the model created for previous questions, call ``predict_proba`` on the test set. Now change the threshold from 0.5 to 0.75, which means if the probability of an instance belongs to class 0 is higher than or equal to 0.75, then the prediction is label 0, otherwise is label 1. \n",
    "\n",
    "Now, what is the auc score of test dataset? (2 significant digits)\n",
    "\n",
    "**Note:** The first index of ``predict_proba`` refers to the probability that the data belong to class 0, and the second refers to the probability that the data belong to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=0.75\n",
    "pred_df = pd.DataFrame( gbrt.predict_proba(X_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['pred'] =  pred_df[0].apply(lambda x: 0 if  x>=thresh else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.983631</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.975435</td>\n",
       "      <td>0.024565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.824839</td>\n",
       "      <td>0.175161</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.973031</td>\n",
       "      <td>0.026969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.664415</td>\n",
       "      <td>0.335585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1  pred\n",
       "0  0.983631  0.016369     0\n",
       "1  0.975435  0.024565     0\n",
       "2  0.824839  0.175161     0\n",
       "3  0.973031  0.026969     0\n",
       "4  0.664415  0.335585     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7973661803446476"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred_df['pred'])\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
