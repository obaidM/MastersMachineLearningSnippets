{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT 2 DEEP LEARNING SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data and clean it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776, 45)\n",
      "the new dimensions are: (776, 32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df1 = pd.read_csv(\"audit_risk.csv\")\n",
    "df2 = pd.read_csv(\"trial.csv\")\n",
    "\n",
    "### combine the two files in one dataframe\n",
    "df = pd.concat([df1, df2], axis=1)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "print(df.shape)\n",
    "\n",
    "## remove duplicate columns \n",
    "df = df.loc[:,~df.columns.duplicated()]\n",
    "print(\"the new dimensions are:\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove Para A , score A, para B, score B , number , score B1 , money value , score_MV ,prob\n",
    "## history ,loss\n",
    "df =  df.drop(['para_a','score_a','para_b','score_b','numbers','score_b.1',\n",
    "               'money_value','score_mv','prob','history','loss','total','marks','district','district_loss'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['location_id'] !='LOHARU')]\n",
    "df = df[(df['location_id'] !='NUH')]\n",
    "df = df[(df['location_id'] !='SAFIDON')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.get_dummies(df['location_id'],columns='location_id',prefix='location_id')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('location_id',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data ready for Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['audit_risk']\n",
    "X = df.drop(['audit_risk','risk'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together \n",
    "X_test = scaler.transform(x_test_org) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 56)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "579/579 [==============================] - 0s 596us/step - loss: 367.6823 - mean_absolute_error: 6.0624\n",
      "Epoch 2/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 362.0764 - mean_absolute_error: 5.8700\n",
      "Epoch 3/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 331.2818 - mean_absolute_error: 5.3114\n",
      "Epoch 4/500\n",
      "579/579 [==============================] - 0s 71us/step - loss: 253.0711 - mean_absolute_error: 4.3287\n",
      "Epoch 5/500\n",
      "579/579 [==============================] - 0s 174us/step - loss: 168.7205 - mean_absolute_error: 3.8315\n",
      "Epoch 6/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 124.8621 - mean_absolute_error: 3.6062\n",
      "Epoch 7/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 106.0701 - mean_absolute_error: 3.0585\n",
      "Epoch 8/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 92.3216 - mean_absolute_error: 2.5630\n",
      "Epoch 9/500\n",
      "579/579 [==============================] - 0s 89us/step - loss: 85.0576 - mean_absolute_error: 2.5617\n",
      "Epoch 10/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 76.0133 - mean_absolute_error: 2.3926\n",
      "Epoch 11/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 71.9077 - mean_absolute_error: 2.1263\n",
      "Epoch 12/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 67.9492 - mean_absolute_error: 2.0682\n",
      "Epoch 13/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 62.8592 - mean_absolute_error: 2.0605\n",
      "Epoch 14/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 58.6446 - mean_absolute_error: 2.0061\n",
      "Epoch 15/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 57.4250 - mean_absolute_error: 1.8503\n",
      "Epoch 16/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 54.1402 - mean_absolute_error: 1.8630\n",
      "Epoch 17/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 52.2251 - mean_absolute_error: 1.8723\n",
      "Epoch 18/500\n",
      "579/579 [==============================] - 0s 153us/step - loss: 49.2140 - mean_absolute_error: 1.7707\n",
      "Epoch 19/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 48.1365 - mean_absolute_error: 1.7480\n",
      "Epoch 20/500\n",
      "579/579 [==============================] - 0s 92us/step - loss: 44.1835 - mean_absolute_error: 1.6859\n",
      "Epoch 21/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 42.1004 - mean_absolute_error: 1.6925\n",
      "Epoch 22/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 41.7334 - mean_absolute_error: 1.6952\n",
      "Epoch 23/500\n",
      "579/579 [==============================] - 0s 120us/step - loss: 37.1907 - mean_absolute_error: 1.6046\n",
      "Epoch 24/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 36.5486 - mean_absolute_error: 1.6554\n",
      "Epoch 25/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 33.0140 - mean_absolute_error: 1.5493\n",
      "Epoch 26/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 31.2167 - mean_absolute_error: 1.5697\n",
      "Epoch 27/500\n",
      "579/579 [==============================] - 0s 75us/step - loss: 29.3654 - mean_absolute_error: 1.4874\n",
      "Epoch 28/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 28.0829 - mean_absolute_error: 1.5122\n",
      "Epoch 29/500\n",
      "579/579 [==============================] - 0s 115us/step - loss: 26.1197 - mean_absolute_error: 1.4815\n",
      "Epoch 30/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 23.6498 - mean_absolute_error: 1.4004\n",
      "Epoch 31/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 21.7438 - mean_absolute_error: 1.4120\n",
      "Epoch 32/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 21.4086 - mean_absolute_error: 1.4243\n",
      "Epoch 33/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 19.2736 - mean_absolute_error: 1.3607\n",
      "Epoch 34/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 16.8764 - mean_absolute_error: 1.3052\n",
      "Epoch 35/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 15.5859 - mean_absolute_error: 1.2488\n",
      "Epoch 36/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 14.7259 - mean_absolute_error: 1.2817\n",
      "Epoch 37/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 13.4149 - mean_absolute_error: 1.2556\n",
      "Epoch 38/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 12.0067 - mean_absolute_error: 1.1932\n",
      "Epoch 39/500\n",
      "579/579 [==============================] - 0s 115us/step - loss: 10.5838 - mean_absolute_error: 1.1425\n",
      "Epoch 40/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 9.5534 - mean_absolute_error: 1.0799\n",
      "Epoch 41/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 8.8344 - mean_absolute_error: 1.0958\n",
      "Epoch 42/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 8.9470 - mean_absolute_error: 1.1024\n",
      "Epoch 43/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 7.3854 - mean_absolute_error: 1.0310\n",
      "Epoch 44/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 6.6980 - mean_absolute_error: 0.9979\n",
      "Epoch 45/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 6.3328 - mean_absolute_error: 0.9821\n",
      "Epoch 46/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 6.0129 - mean_absolute_error: 0.9787\n",
      "Epoch 47/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 5.4982 - mean_absolute_error: 0.9636\n",
      "Epoch 48/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 5.4250 - mean_absolute_error: 0.9397\n",
      "Epoch 49/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 4.5241 - mean_absolute_error: 0.8819\n",
      "Epoch 50/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 4.0224 - mean_absolute_error: 0.8428\n",
      "Epoch 51/500\n",
      "579/579 [==============================] - 0s 121us/step - loss: 3.8850 - mean_absolute_error: 0.8175\n",
      "Epoch 52/500\n",
      "579/579 [==============================] - 0s 121us/step - loss: 3.4155 - mean_absolute_error: 0.7941\n",
      "Epoch 53/500\n",
      "579/579 [==============================] - 0s 119us/step - loss: 3.3788 - mean_absolute_error: 0.7810\n",
      "Epoch 54/500\n",
      "579/579 [==============================] - 0s 121us/step - loss: 3.1226 - mean_absolute_error: 0.7481\n",
      "Epoch 55/500\n",
      "579/579 [==============================] - 0s 114us/step - loss: 3.1257 - mean_absolute_error: 0.7593\n",
      "Epoch 56/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 2.8849 - mean_absolute_error: 0.7441\n",
      "Epoch 57/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 2.7490 - mean_absolute_error: 0.7161\n",
      "Epoch 58/500\n",
      "579/579 [==============================] - 0s 124us/step - loss: 2.3564 - mean_absolute_error: 0.7023\n",
      "Epoch 59/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 2.4528 - mean_absolute_error: 0.7184\n",
      "Epoch 60/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 2.3790 - mean_absolute_error: 0.6903\n",
      "Epoch 61/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 2.1581 - mean_absolute_error: 0.6692\n",
      "Epoch 62/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.2941 - mean_absolute_error: 0.6692\n",
      "Epoch 63/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 2.0947 - mean_absolute_error: 0.6582\n",
      "Epoch 64/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.0056 - mean_absolute_error: 0.6555\n",
      "Epoch 65/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 1.8499 - mean_absolute_error: 0.6265\n",
      "Epoch 66/500\n",
      "579/579 [==============================] - 0s 115us/step - loss: 1.7501 - mean_absolute_error: 0.6162\n",
      "Epoch 67/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.8181 - mean_absolute_error: 0.6344\n",
      "Epoch 68/500\n",
      "579/579 [==============================] - 0s 106us/step - loss: 1.6654 - mean_absolute_error: 0.6081\n",
      "Epoch 69/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.6497 - mean_absolute_error: 0.6016\n",
      "Epoch 70/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.6473 - mean_absolute_error: 0.5967\n",
      "Epoch 71/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.4330 - mean_absolute_error: 0.5671\n",
      "Epoch 72/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 1.6485 - mean_absolute_error: 0.5920\n",
      "Epoch 73/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.5366 - mean_absolute_error: 0.6040\n",
      "Epoch 74/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.3812 - mean_absolute_error: 0.5725\n",
      "Epoch 75/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 1.3955 - mean_absolute_error: 0.5584\n",
      "Epoch 76/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.2422 - mean_absolute_error: 0.5439\n",
      "Epoch 77/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.2657 - mean_absolute_error: 0.5429\n",
      "Epoch 78/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.3724 - mean_absolute_error: 0.5506\n",
      "Epoch 79/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 1.1565 - mean_absolute_error: 0.5192\n",
      "Epoch 80/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 1.1144 - mean_absolute_error: 0.5126\n",
      "Epoch 81/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.4136 - mean_absolute_error: 0.5390\n",
      "Epoch 82/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.0633 - mean_absolute_error: 0.5201\n",
      "Epoch 83/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.1826 - mean_absolute_error: 0.5378\n",
      "Epoch 84/500\n",
      "579/579 [==============================] - 0s 115us/step - loss: 1.1409 - mean_absolute_error: 0.5254\n",
      "Epoch 85/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 1.0075 - mean_absolute_error: 0.4879\n",
      "Epoch 86/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.9344 - mean_absolute_error: 0.4897\n",
      "Epoch 87/500\n",
      "579/579 [==============================] - 0s 108us/step - loss: 1.0603 - mean_absolute_error: 0.5052\n",
      "Epoch 88/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9621 - mean_absolute_error: 0.5096\n",
      "Epoch 89/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.9432 - mean_absolute_error: 0.4866\n",
      "Epoch 90/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.9583 - mean_absolute_error: 0.5087\n",
      "Epoch 91/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9087 - mean_absolute_error: 0.4885\n",
      "Epoch 92/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8919 - mean_absolute_error: 0.4908\n",
      "Epoch 93/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.8781 - mean_absolute_error: 0.4925\n",
      "Epoch 94/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 1.0956 - mean_absolute_error: 0.5109\n",
      "Epoch 95/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9866 - mean_absolute_error: 0.5125\n",
      "Epoch 96/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.9130 - mean_absolute_error: 0.4838\n",
      "Epoch 97/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7905 - mean_absolute_error: 0.4636\n",
      "Epoch 98/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7465 - mean_absolute_error: 0.4446\n",
      "Epoch 99/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.9492 - mean_absolute_error: 0.5060\n",
      "Epoch 100/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.8513 - mean_absolute_error: 0.4851\n",
      "Epoch 101/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6397 - mean_absolute_error: 0.4365\n",
      "Epoch 102/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.6671 - mean_absolute_error: 0.4346\n",
      "Epoch 103/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7527 - mean_absolute_error: 0.4570\n",
      "Epoch 104/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7036 - mean_absolute_error: 0.4470\n",
      "Epoch 105/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.7298 - mean_absolute_error: 0.4546\n",
      "Epoch 106/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.8063 - mean_absolute_error: 0.4740\n",
      "Epoch 107/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.0199 - mean_absolute_error: 0.5175\n",
      "Epoch 108/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.7952 - mean_absolute_error: 0.4842\n",
      "Epoch 109/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.7891 - mean_absolute_error: 0.4792\n",
      "Epoch 110/500\n",
      "579/579 [==============================] - 0s 67us/step - loss: 0.9724 - mean_absolute_error: 0.4959\n",
      "Epoch 111/500\n",
      "579/579 [==============================] - 0s 118us/step - loss: 0.8385 - mean_absolute_error: 0.4733\n",
      "Epoch 112/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6528 - mean_absolute_error: 0.4430\n",
      "Epoch 113/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.5932 - mean_absolute_error: 0.4226\n",
      "Epoch 114/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.5307 - mean_absolute_error: 0.4075\n",
      "Epoch 115/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5807 - mean_absolute_error: 0.4185\n",
      "Epoch 116/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.5325 - mean_absolute_error: 0.3850\n",
      "Epoch 117/500\n",
      "579/579 [==============================] - 0s 118us/step - loss: 0.5084 - mean_absolute_error: 0.3963\n",
      "Epoch 118/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.4440 - mean_absolute_error: 0.3698\n",
      "Epoch 119/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4717 - mean_absolute_error: 0.3784\n",
      "Epoch 120/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4984 - mean_absolute_error: 0.3936\n",
      "Epoch 121/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.4882 - mean_absolute_error: 0.3908\n",
      "Epoch 122/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5554 - mean_absolute_error: 0.3975\n",
      "Epoch 123/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7618 - mean_absolute_error: 0.4553\n",
      "Epoch 124/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 4.5537 - mean_absolute_error: 0.8409\n",
      "Epoch 125/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 2.0894 - mean_absolute_error: 0.6665\n",
      "Epoch 126/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.7948 - mean_absolute_error: 0.4659\n",
      "Epoch 127/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.0175 - mean_absolute_error: 0.4992\n",
      "Epoch 128/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.7325 - mean_absolute_error: 0.4533\n",
      "Epoch 129/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.4658 - mean_absolute_error: 0.3847\n",
      "Epoch 130/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4391 - mean_absolute_error: 0.3753\n",
      "Epoch 131/500\n",
      "579/579 [==============================] - 0s 77us/step - loss: 0.3965 - mean_absolute_error: 0.3587\n",
      "Epoch 132/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5555 - mean_absolute_error: 0.4112\n",
      "Epoch 133/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.5564 - mean_absolute_error: 0.4047\n",
      "Epoch 134/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.4792 - mean_absolute_error: 0.3964\n",
      "Epoch 135/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.3918 - mean_absolute_error: 0.3621\n",
      "Epoch 136/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.3795 - mean_absolute_error: 0.3517\n",
      "Epoch 137/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4136 - mean_absolute_error: 0.3594\n",
      "Epoch 138/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.3444 - mean_absolute_error: 0.3422\n",
      "Epoch 139/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3949 - mean_absolute_error: 0.3519\n",
      "Epoch 140/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.3541 - mean_absolute_error: 0.3536\n",
      "Epoch 141/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5323 - mean_absolute_error: 0.3986\n",
      "Epoch 142/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.5216 - mean_absolute_error: 0.3923\n",
      "Epoch 143/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 102us/step - loss: 0.7565 - mean_absolute_error: 0.4178\n",
      "Epoch 144/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.5712 - mean_absolute_error: 0.4060\n",
      "Epoch 145/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5653 - mean_absolute_error: 0.4022\n",
      "Epoch 146/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4196 - mean_absolute_error: 0.3606\n",
      "Epoch 147/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.4555 - mean_absolute_error: 0.3726\n",
      "Epoch 148/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.5754 - mean_absolute_error: 0.3977\n",
      "Epoch 149/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.4948 - mean_absolute_error: 0.3868\n",
      "Epoch 150/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6233 - mean_absolute_error: 0.4037\n",
      "Epoch 151/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6648 - mean_absolute_error: 0.4191\n",
      "Epoch 152/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 0.7264 - mean_absolute_error: 0.4325\n",
      "Epoch 153/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.6905 - mean_absolute_error: 0.4366\n",
      "Epoch 154/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.5594 - mean_absolute_error: 0.4138\n",
      "Epoch 155/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6948 - mean_absolute_error: 0.4406\n",
      "Epoch 156/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.6909 - mean_absolute_error: 0.4281\n",
      "Epoch 157/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.6805 - mean_absolute_error: 0.4136\n",
      "Epoch 158/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6851 - mean_absolute_error: 0.4120\n",
      "Epoch 159/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.4492 - mean_absolute_error: 0.3526\n",
      "Epoch 160/500\n",
      "579/579 [==============================] - 0s 73us/step - loss: 0.3217 - mean_absolute_error: 0.3337\n",
      "Epoch 161/500\n",
      "579/579 [==============================] - 0s 104us/step - loss: 0.4069 - mean_absolute_error: 0.3524\n",
      "Epoch 162/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.3917 - mean_absolute_error: 0.3520\n",
      "Epoch 163/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5488 - mean_absolute_error: 0.3714\n",
      "Epoch 164/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5556 - mean_absolute_error: 0.3810\n",
      "Epoch 165/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.3182 - mean_absolute_error: 0.3309\n",
      "Epoch 166/500\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.2949 - mean_absolute_error: 0.3270\n",
      "Epoch 167/500\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.3940 - mean_absolute_error: 0.3551\n",
      "Epoch 168/500\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.4798 - mean_absolute_error: 0.3673\n",
      "Epoch 169/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 1.0753 - mean_absolute_error: 0.4762\n",
      "Epoch 170/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.6328 - mean_absolute_error: 0.4024\n",
      "Epoch 171/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.8358 - mean_absolute_error: 0.4340\n",
      "Epoch 172/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.5233 - mean_absolute_error: 0.3875\n",
      "Epoch 173/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5748 - mean_absolute_error: 0.3860\n",
      "Epoch 174/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.4228 - mean_absolute_error: 0.3477\n",
      "Epoch 175/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3965 - mean_absolute_error: 0.3477\n",
      "Epoch 176/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.3709 - mean_absolute_error: 0.3376\n",
      "Epoch 177/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.4035 - mean_absolute_error: 0.3498\n",
      "Epoch 178/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.3883 - mean_absolute_error: 0.3306\n",
      "Epoch 179/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.4439 - mean_absolute_error: 0.3529\n",
      "Epoch 180/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.4054 - mean_absolute_error: 0.3455\n",
      "Epoch 181/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5456 - mean_absolute_error: 0.3846\n",
      "Epoch 182/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.3575 - mean_absolute_error: 0.3485\n",
      "Epoch 183/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3093 - mean_absolute_error: 0.3294\n",
      "Epoch 184/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.3980 - mean_absolute_error: 0.3533\n",
      "Epoch 185/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.5579 - mean_absolute_error: 0.3820\n",
      "Epoch 186/500\n",
      "579/579 [==============================] - 0s 108us/step - loss: 0.7963 - mean_absolute_error: 0.4155\n",
      "Epoch 187/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.3414 - mean_absolute_error: 0.4840\n",
      "Epoch 188/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.7023 - mean_absolute_error: 0.4206\n",
      "Epoch 189/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.4479 - mean_absolute_error: 0.3552\n",
      "Epoch 190/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.3519 - mean_absolute_error: 0.3329\n",
      "Epoch 191/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4164 - mean_absolute_error: 0.3383\n",
      "Epoch 192/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.8298 - mean_absolute_error: 0.4424\n",
      "Epoch 193/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6414 - mean_absolute_error: 0.4183\n",
      "Epoch 194/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3782 - mean_absolute_error: 0.3521\n",
      "Epoch 195/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.3719 - mean_absolute_error: 0.3395\n",
      "Epoch 196/500\n",
      "579/579 [==============================] - 0s 99us/step - loss: 0.4480 - mean_absolute_error: 0.3643\n",
      "Epoch 197/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4716 - mean_absolute_error: 0.3596\n",
      "Epoch 198/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.3970 - mean_absolute_error: 0.3517\n",
      "Epoch 199/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.3249 - mean_absolute_error: 0.3324\n",
      "Epoch 200/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4043 - mean_absolute_error: 0.3481\n",
      "Epoch 201/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3492 - mean_absolute_error: 0.3401\n",
      "Epoch 202/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.3188 - mean_absolute_error: 0.3257\n",
      "Epoch 203/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.3494 - mean_absolute_error: 0.3339\n",
      "Epoch 204/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.3542 - mean_absolute_error: 0.3246\n",
      "Epoch 205/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5461 - mean_absolute_error: 0.3890\n",
      "Epoch 206/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.5054 - mean_absolute_error: 0.3608\n",
      "Epoch 207/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.5543 - mean_absolute_error: 0.3753\n",
      "Epoch 208/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.5724 - mean_absolute_error: 0.3855\n",
      "Epoch 209/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9914 - mean_absolute_error: 0.4463\n",
      "Epoch 210/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 2.1525 - mean_absolute_error: 0.5908\n",
      "Epoch 211/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 1.1313 - mean_absolute_error: 0.5162\n",
      "Epoch 212/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8953 - mean_absolute_error: 0.4466\n",
      "Epoch 213/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5244 - mean_absolute_error: 0.3680\n",
      "Epoch 214/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.4307 - mean_absolute_error: 0.3522\n",
      "Epoch 215/500\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.2738 - mean_absolute_error: 0.3012\n",
      "Epoch 216/500\n",
      "579/579 [==============================] - 0s 71us/step - loss: 0.2206 - mean_absolute_error: 0.2855\n",
      "Epoch 217/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.3547 - mean_absolute_error: 0.3270\n",
      "Epoch 218/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4058 - mean_absolute_error: 0.3361\n",
      "Epoch 219/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.3546 - mean_absolute_error: 0.3343\n",
      "Epoch 220/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.3740 - mean_absolute_error: 0.3084\n",
      "Epoch 221/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.3297 - mean_absolute_error: 0.3121\n",
      "Epoch 222/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2534 - mean_absolute_error: 0.2823\n",
      "Epoch 223/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2267 - mean_absolute_error: 0.2816\n",
      "Epoch 224/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2271 - mean_absolute_error: 0.2785\n",
      "Epoch 225/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2111 - mean_absolute_error: 0.2786\n",
      "Epoch 226/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.2195 - mean_absolute_error: 0.2763\n",
      "Epoch 227/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2708 - mean_absolute_error: 0.2888\n",
      "Epoch 228/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6464 - mean_absolute_error: 0.3826\n",
      "Epoch 229/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.3051 - mean_absolute_error: 0.4771\n",
      "Epoch 230/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7844 - mean_absolute_error: 0.4571\n",
      "Epoch 231/500\n",
      "579/579 [==============================] - 0s 68us/step - loss: 0.5230 - mean_absolute_error: 0.3638\n",
      "Epoch 232/500\n",
      "579/579 [==============================] - 0s 106us/step - loss: 0.6315 - mean_absolute_error: 0.4014\n",
      "Epoch 233/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6104 - mean_absolute_error: 0.3907\n",
      "Epoch 234/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.3469 - mean_absolute_error: 0.3297\n",
      "Epoch 235/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.3099 - mean_absolute_error: 0.3132\n",
      "Epoch 236/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.3691 - mean_absolute_error: 0.3162\n",
      "Epoch 237/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.3509 - mean_absolute_error: 0.3063\n",
      "Epoch 238/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.2750 - mean_absolute_error: 0.2836\n",
      "Epoch 239/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.2504 - mean_absolute_error: 0.2853\n",
      "Epoch 240/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.2956 - mean_absolute_error: 0.2974\n",
      "Epoch 241/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.2668 - mean_absolute_error: 0.2908\n",
      "Epoch 242/500\n",
      "579/579 [==============================] - 0s 131us/step - loss: 0.1919 - mean_absolute_error: 0.2663\n",
      "Epoch 243/500\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.2041 - mean_absolute_error: 0.2730\n",
      "Epoch 244/500\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.3571 - mean_absolute_error: 0.3105\n",
      "Epoch 245/500\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.8114 - mean_absolute_error: 0.3762\n",
      "Epoch 246/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.2468 - mean_absolute_error: 0.4725\n",
      "Epoch 247/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 3.6534 - mean_absolute_error: 0.7284\n",
      "Epoch 248/500\n",
      "579/579 [==============================] - 0s 127us/step - loss: 1.4943 - mean_absolute_error: 0.5762\n",
      "Epoch 249/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5933 - mean_absolute_error: 0.3746\n",
      "Epoch 250/500\n",
      "579/579 [==============================] - 0s 54us/step - loss: 0.4100 - mean_absolute_error: 0.3472\n",
      "Epoch 251/500\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.2807 - mean_absolute_error: 0.3077\n",
      "Epoch 252/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.2979 - mean_absolute_error: 0.2994\n",
      "Epoch 253/500\n",
      "579/579 [==============================] - 0s 138us/step - loss: 0.2719 - mean_absolute_error: 0.2867\n",
      "Epoch 254/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.2125 - mean_absolute_error: 0.2739\n",
      "Epoch 255/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.1751 - mean_absolute_error: 0.2545\n",
      "Epoch 256/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1887 - mean_absolute_error: 0.2600\n",
      "Epoch 257/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2051 - mean_absolute_error: 0.2649\n",
      "Epoch 258/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1984 - mean_absolute_error: 0.2580\n",
      "Epoch 259/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1767 - mean_absolute_error: 0.2539\n",
      "Epoch 260/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1647 - mean_absolute_error: 0.2437\n",
      "Epoch 261/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1728 - mean_absolute_error: 0.2425\n",
      "Epoch 262/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1788 - mean_absolute_error: 0.2570\n",
      "Epoch 263/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.2474 - mean_absolute_error: 0.2798\n",
      "Epoch 264/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2503 - mean_absolute_error: 0.2783\n",
      "Epoch 265/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4190 - mean_absolute_error: 0.3230\n",
      "Epoch 266/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.3019 - mean_absolute_error: 0.2976\n",
      "Epoch 267/500\n",
      "579/579 [==============================] - 0s 137us/step - loss: 0.4419 - mean_absolute_error: 0.3335\n",
      "Epoch 268/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.3120 - mean_absolute_error: 0.3017\n",
      "Epoch 269/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.4425 - mean_absolute_error: 0.3470\n",
      "Epoch 270/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.7203 - mean_absolute_error: 0.3928\n",
      "Epoch 271/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.9661 - mean_absolute_error: 0.4255\n",
      "Epoch 272/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6544 - mean_absolute_error: 0.3823\n",
      "Epoch 273/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.7985 - mean_absolute_error: 0.4013\n",
      "Epoch 274/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6755 - mean_absolute_error: 0.3805\n",
      "Epoch 275/500\n",
      "579/579 [==============================] - 0s 71us/step - loss: 0.8479 - mean_absolute_error: 0.4075\n",
      "Epoch 276/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5486 - mean_absolute_error: 0.3638\n",
      "Epoch 277/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.4197 - mean_absolute_error: 0.3173\n",
      "Epoch 278/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6024 - mean_absolute_error: 0.3624\n",
      "Epoch 279/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4624 - mean_absolute_error: 0.3385\n",
      "Epoch 280/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5328 - mean_absolute_error: 0.3288\n",
      "Epoch 281/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.4331 - mean_absolute_error: 0.3145\n",
      "Epoch 282/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.5949 - mean_absolute_error: 0.3464\n",
      "Epoch 283/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.3514 - mean_absolute_error: 0.2810\n",
      "Epoch 284/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.2563 - mean_absolute_error: 0.2688\n",
      "Epoch 285/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 95us/step - loss: 0.3097 - mean_absolute_error: 0.2734\n",
      "Epoch 286/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6845 - mean_absolute_error: 0.3935\n",
      "Epoch 287/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.2912 - mean_absolute_error: 0.2906\n",
      "Epoch 288/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1944 - mean_absolute_error: 0.2568\n",
      "Epoch 289/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.1443 - mean_absolute_error: 0.2314\n",
      "Epoch 290/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2133 - mean_absolute_error: 0.2613\n",
      "Epoch 291/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.3227 - mean_absolute_error: 0.3152\n",
      "Epoch 292/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2083 - mean_absolute_error: 0.2619\n",
      "Epoch 293/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.1620 - mean_absolute_error: 0.2321\n",
      "Epoch 294/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1400 - mean_absolute_error: 0.2191\n",
      "Epoch 295/500\n",
      "579/579 [==============================] - 0s 99us/step - loss: 0.1508 - mean_absolute_error: 0.2334\n",
      "Epoch 296/500\n",
      "579/579 [==============================] - 0s 73us/step - loss: 0.1400 - mean_absolute_error: 0.2272\n",
      "Epoch 297/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1899 - mean_absolute_error: 0.2418\n",
      "Epoch 298/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.2624 - mean_absolute_error: 0.2719\n",
      "Epoch 299/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.2878 - mean_absolute_error: 0.2743\n",
      "Epoch 300/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.4077 - mean_absolute_error: 0.3230\n",
      "Epoch 301/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7362 - mean_absolute_error: 0.3853\n",
      "Epoch 302/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.2002 - mean_absolute_error: 0.4411\n",
      "Epoch 303/500\n",
      "579/579 [==============================] - 0s 68us/step - loss: 1.3254 - mean_absolute_error: 0.4967\n",
      "Epoch 304/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 1.9262 - mean_absolute_error: 0.6027\n",
      "Epoch 305/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.8408 - mean_absolute_error: 0.3807\n",
      "Epoch 306/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6502 - mean_absolute_error: 0.3669\n",
      "Epoch 307/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.3001 - mean_absolute_error: 0.2916\n",
      "Epoch 308/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4404 - mean_absolute_error: 0.3086\n",
      "Epoch 309/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.8497 - mean_absolute_error: 0.3778\n",
      "Epoch 310/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9642 - mean_absolute_error: 0.4124\n",
      "Epoch 311/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.3580 - mean_absolute_error: 0.4566\n",
      "Epoch 312/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 1.6235 - mean_absolute_error: 0.4765\n",
      "Epoch 313/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4701 - mean_absolute_error: 0.3249\n",
      "Epoch 314/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.3956 - mean_absolute_error: 0.3021\n",
      "Epoch 315/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2116 - mean_absolute_error: 0.2511\n",
      "Epoch 316/500\n",
      "579/579 [==============================] - 0s 89us/step - loss: 0.2888 - mean_absolute_error: 0.2726\n",
      "Epoch 317/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2830 - mean_absolute_error: 0.2835\n",
      "Epoch 318/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.2058 - mean_absolute_error: 0.2577\n",
      "Epoch 319/500\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.1475 - mean_absolute_error: 0.2254\n",
      "Epoch 320/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.1341 - mean_absolute_error: 0.2217\n",
      "Epoch 321/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.1222 - mean_absolute_error: 0.2079\n",
      "Epoch 322/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.1427 - mean_absolute_error: 0.2226\n",
      "Epoch 323/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1180 - mean_absolute_error: 0.2064\n",
      "Epoch 324/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1237 - mean_absolute_error: 0.2040\n",
      "Epoch 325/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1324 - mean_absolute_error: 0.2125\n",
      "Epoch 326/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1396 - mean_absolute_error: 0.2177\n",
      "Epoch 327/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.1327 - mean_absolute_error: 0.2149\n",
      "Epoch 328/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1145 - mean_absolute_error: 0.2033\n",
      "Epoch 329/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.1170 - mean_absolute_error: 0.2095\n",
      "Epoch 330/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.1212 - mean_absolute_error: 0.2090\n",
      "Epoch 331/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.1315 - mean_absolute_error: 0.2155\n",
      "Epoch 332/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.1543 - mean_absolute_error: 0.2335\n",
      "Epoch 333/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.2299 - mean_absolute_error: 0.2590\n",
      "Epoch 334/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3388 - mean_absolute_error: 0.3028\n",
      "Epoch 335/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5524 - mean_absolute_error: 0.3398\n",
      "Epoch 336/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.1027 - mean_absolute_error: 0.4018\n",
      "Epoch 337/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.9800 - mean_absolute_error: 0.5350\n",
      "Epoch 338/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.1426 - mean_absolute_error: 0.4490\n",
      "Epoch 339/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 2.3072 - mean_absolute_error: 0.5311\n",
      "Epoch 340/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.7126 - mean_absolute_error: 0.3742\n",
      "Epoch 341/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4589 - mean_absolute_error: 0.3356\n",
      "Epoch 342/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.4546 - mean_absolute_error: 0.3105\n",
      "Epoch 343/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.3897 - mean_absolute_error: 0.3007\n",
      "Epoch 344/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1895 - mean_absolute_error: 0.2467\n",
      "Epoch 345/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.2093 - mean_absolute_error: 0.2435\n",
      "Epoch 346/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1397 - mean_absolute_error: 0.2234\n",
      "Epoch 347/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1294 - mean_absolute_error: 0.2164\n",
      "Epoch 348/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1154 - mean_absolute_error: 0.2017\n",
      "Epoch 349/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.1137 - mean_absolute_error: 0.2042\n",
      "Epoch 350/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.0979 - mean_absolute_error: 0.1930\n",
      "Epoch 351/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1219 - mean_absolute_error: 0.2082\n",
      "Epoch 352/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1059 - mean_absolute_error: 0.1947\n",
      "Epoch 353/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1245 - mean_absolute_error: 0.2091\n",
      "Epoch 354/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1328 - mean_absolute_error: 0.2087\n",
      "Epoch 355/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1629 - mean_absolute_error: 0.2224\n",
      "Epoch 356/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3914 - mean_absolute_error: 0.2869\n",
      "Epoch 357/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.5344 - mean_absolute_error: 0.3222\n",
      "Epoch 358/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.3652 - mean_absolute_error: 0.2917\n",
      "Epoch 359/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.4021 - mean_absolute_error: 0.2991\n",
      "Epoch 360/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2568 - mean_absolute_error: 0.2589\n",
      "Epoch 361/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.2197 - mean_absolute_error: 0.2493\n",
      "Epoch 362/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2110 - mean_absolute_error: 0.2493\n",
      "Epoch 363/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.1851 - mean_absolute_error: 0.2427\n",
      "Epoch 364/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.3209 - mean_absolute_error: 0.2711\n",
      "Epoch 365/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.3309 - mean_absolute_error: 0.2949\n",
      "Epoch 366/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.3437 - mean_absolute_error: 0.3055\n",
      "Epoch 367/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5102 - mean_absolute_error: 0.3511\n",
      "Epoch 368/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.5747 - mean_absolute_error: 0.3406\n",
      "Epoch 369/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 1.9640 - mean_absolute_error: 0.5561\n",
      "Epoch 370/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 2.4185 - mean_absolute_error: 0.5821\n",
      "Epoch 371/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.2312 - mean_absolute_error: 0.4549\n",
      "Epoch 372/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.7319 - mean_absolute_error: 0.3587\n",
      "Epoch 373/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3838 - mean_absolute_error: 0.3073\n",
      "Epoch 374/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.2408 - mean_absolute_error: 0.2599\n",
      "Epoch 375/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.1998 - mean_absolute_error: 0.2340\n",
      "Epoch 376/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1334 - mean_absolute_error: 0.2134\n",
      "Epoch 377/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.1157 - mean_absolute_error: 0.2064\n",
      "Epoch 378/500\n",
      "579/579 [==============================] - 0s 144us/step - loss: 0.1078 - mean_absolute_error: 0.1990\n",
      "Epoch 379/500\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.1234 - mean_absolute_error: 0.2021\n",
      "Epoch 380/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.1257 - mean_absolute_error: 0.2070\n",
      "Epoch 381/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.1001 - mean_absolute_error: 0.1916\n",
      "Epoch 382/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.1541 - mean_absolute_error: 0.2137\n",
      "Epoch 383/500\n",
      "579/579 [==============================] - 0s 92us/step - loss: 0.1296 - mean_absolute_error: 0.2090\n",
      "Epoch 384/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.1115 - mean_absolute_error: 0.1990\n",
      "Epoch 385/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.0914 - mean_absolute_error: 0.1858\n",
      "Epoch 386/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0864 - mean_absolute_error: 0.1777\n",
      "Epoch 387/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.0852 - mean_absolute_error: 0.1766\n",
      "Epoch 388/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0983 - mean_absolute_error: 0.1850\n",
      "Epoch 389/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1616 - mean_absolute_error: 0.2321\n",
      "Epoch 390/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.2586 - mean_absolute_error: 0.2677\n",
      "Epoch 391/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2112 - mean_absolute_error: 0.2443\n",
      "Epoch 392/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.3681 - mean_absolute_error: 0.2876\n",
      "Epoch 393/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.7990 - mean_absolute_error: 0.3891\n",
      "Epoch 394/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9981 - mean_absolute_error: 0.4192\n",
      "Epoch 395/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 2.4811 - mean_absolute_error: 0.5887\n",
      "Epoch 396/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.9863 - mean_absolute_error: 0.5202\n",
      "Epoch 397/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7391 - mean_absolute_error: 0.3776\n",
      "Epoch 398/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.3410 - mean_absolute_error: 0.2794\n",
      "Epoch 399/500\n",
      "579/579 [==============================] - 0s 104us/step - loss: 0.4698 - mean_absolute_error: 0.3311\n",
      "Epoch 400/500\n",
      "579/579 [==============================] - 0s 140us/step - loss: 0.3010 - mean_absolute_error: 0.2727\n",
      "Epoch 401/500\n",
      "579/579 [==============================] - 0s 150us/step - loss: 0.1223 - mean_absolute_error: 0.2104\n",
      "Epoch 402/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.1016 - mean_absolute_error: 0.1996\n",
      "Epoch 403/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.1232 - mean_absolute_error: 0.2128\n",
      "Epoch 404/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.1230 - mean_absolute_error: 0.2100\n",
      "Epoch 405/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0997 - mean_absolute_error: 0.1918\n",
      "Epoch 406/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.0914 - mean_absolute_error: 0.1833\n",
      "Epoch 407/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.0950 - mean_absolute_error: 0.1899\n",
      "Epoch 408/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1346 - mean_absolute_error: 0.2059\n",
      "Epoch 409/500\n",
      "579/579 [==============================] - 0s 70us/step - loss: 0.1296 - mean_absolute_error: 0.2029\n",
      "Epoch 410/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 0.1113 - mean_absolute_error: 0.2021\n",
      "Epoch 411/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1154 - mean_absolute_error: 0.2034\n",
      "Epoch 412/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1867 - mean_absolute_error: 0.2309\n",
      "Epoch 413/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3355 - mean_absolute_error: 0.2791\n",
      "Epoch 414/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.2582 - mean_absolute_error: 0.2525\n",
      "Epoch 415/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1560 - mean_absolute_error: 0.2307\n",
      "Epoch 416/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2020 - mean_absolute_error: 0.2310\n",
      "Epoch 417/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 1.4659 - mean_absolute_error: 0.3946\n",
      "Epoch 418/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.0722 - mean_absolute_error: 0.4376\n",
      "Epoch 419/500\n",
      "579/579 [==============================] - 0s 70us/step - loss: 1.2727 - mean_absolute_error: 0.4884\n",
      "Epoch 420/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 1.0856 - mean_absolute_error: 0.4542\n",
      "Epoch 421/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5729 - mean_absolute_error: 0.3416\n",
      "Epoch 422/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.2868 - mean_absolute_error: 0.2711\n",
      "Epoch 423/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.1795 - mean_absolute_error: 0.2356\n",
      "Epoch 424/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.1163 - mean_absolute_error: 0.2012\n",
      "Epoch 425/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.0956 - mean_absolute_error: 0.1857\n",
      "Epoch 426/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.0909 - mean_absolute_error: 0.1827\n",
      "Epoch 427/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 83us/step - loss: 0.0834 - mean_absolute_error: 0.1750\n",
      "Epoch 428/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0885 - mean_absolute_error: 0.1803\n",
      "Epoch 429/500\n",
      "579/579 [==============================] - 0s 74us/step - loss: 0.0895 - mean_absolute_error: 0.1770\n",
      "Epoch 430/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1166 - mean_absolute_error: 0.1996\n",
      "Epoch 431/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.3190 - mean_absolute_error: 0.2584\n",
      "Epoch 432/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.6424 - mean_absolute_error: 0.3444\n",
      "Epoch 433/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.5468 - mean_absolute_error: 0.3506\n",
      "Epoch 434/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.6832 - mean_absolute_error: 0.3602\n",
      "Epoch 435/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.3082 - mean_absolute_error: 0.2947\n",
      "Epoch 436/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.2124 - mean_absolute_error: 0.2363\n",
      "Epoch 437/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.1303 - mean_absolute_error: 0.2091\n",
      "Epoch 438/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.3585 - mean_absolute_error: 0.2762\n",
      "Epoch 439/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.2311 - mean_absolute_error: 0.2637\n",
      "Epoch 440/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.1530 - mean_absolute_error: 0.2229\n",
      "Epoch 441/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.2246 - mean_absolute_error: 0.2386\n",
      "Epoch 442/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.2358 - mean_absolute_error: 0.2491\n",
      "Epoch 443/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3234 - mean_absolute_error: 0.2677\n",
      "Epoch 444/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4695 - mean_absolute_error: 0.3220\n",
      "Epoch 445/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.4831 - mean_absolute_error: 0.3178\n",
      "Epoch 446/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.6888 - mean_absolute_error: 0.3721\n",
      "Epoch 447/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.0172 - mean_absolute_error: 0.4151\n",
      "Epoch 448/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.8462 - mean_absolute_error: 0.3613\n",
      "Epoch 449/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.7318 - mean_absolute_error: 0.4673\n",
      "Epoch 450/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.8880 - mean_absolute_error: 0.3744\n",
      "Epoch 451/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.6164 - mean_absolute_error: 0.3451\n",
      "Epoch 452/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6591 - mean_absolute_error: 0.3424\n",
      "Epoch 453/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.2550 - mean_absolute_error: 0.2545\n",
      "Epoch 454/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2044 - mean_absolute_error: 0.2342\n",
      "Epoch 455/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.4115 - mean_absolute_error: 0.3006\n",
      "Epoch 456/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.2576 - mean_absolute_error: 0.2587\n",
      "Epoch 457/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2414 - mean_absolute_error: 0.2572\n",
      "Epoch 458/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1545 - mean_absolute_error: 0.2261\n",
      "Epoch 459/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2702 - mean_absolute_error: 0.2538\n",
      "Epoch 460/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2849 - mean_absolute_error: 0.2706\n",
      "Epoch 461/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2492 - mean_absolute_error: 0.2408\n",
      "Epoch 462/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.1508 - mean_absolute_error: 0.2210\n",
      "Epoch 463/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.1611 - mean_absolute_error: 0.2208\n",
      "Epoch 464/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0856 - mean_absolute_error: 0.1799\n",
      "Epoch 465/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.0759 - mean_absolute_error: 0.1716\n",
      "Epoch 466/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.0849 - mean_absolute_error: 0.1760\n",
      "Epoch 467/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.0831 - mean_absolute_error: 0.1780\n",
      "Epoch 468/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1171 - mean_absolute_error: 0.2008\n",
      "Epoch 469/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.3050 - mean_absolute_error: 0.2471\n",
      "Epoch 470/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2838 - mean_absolute_error: 0.2483\n",
      "Epoch 471/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.2374 - mean_absolute_error: 0.2553\n",
      "Epoch 472/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5227 - mean_absolute_error: 0.3074\n",
      "Epoch 473/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.9932 - mean_absolute_error: 0.3933\n",
      "Epoch 474/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 1.6069 - mean_absolute_error: 0.5016\n",
      "Epoch 475/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.8391 - mean_absolute_error: 0.5027\n",
      "Epoch 476/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6766 - mean_absolute_error: 0.3523\n",
      "Epoch 477/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6236 - mean_absolute_error: 0.3508\n",
      "Epoch 478/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2305 - mean_absolute_error: 0.2486\n",
      "Epoch 479/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.1747 - mean_absolute_error: 0.2359\n",
      "Epoch 480/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1216 - mean_absolute_error: 0.1995\n",
      "Epoch 481/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.1063 - mean_absolute_error: 0.1963\n",
      "Epoch 482/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.0933 - mean_absolute_error: 0.1774\n",
      "Epoch 483/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.0887 - mean_absolute_error: 0.1767\n",
      "Epoch 484/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0908 - mean_absolute_error: 0.1814\n",
      "Epoch 485/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0744 - mean_absolute_error: 0.1697\n",
      "Epoch 486/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0804 - mean_absolute_error: 0.1722\n",
      "Epoch 487/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1182 - mean_absolute_error: 0.1921\n",
      "Epoch 488/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.2375 - mean_absolute_error: 0.2453\n",
      "Epoch 489/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.2634 - mean_absolute_error: 0.2534\n",
      "Epoch 490/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1407 - mean_absolute_error: 0.2194\n",
      "Epoch 491/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1310 - mean_absolute_error: 0.2126\n",
      "Epoch 492/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1032 - mean_absolute_error: 0.1969\n",
      "Epoch 493/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1920 - mean_absolute_error: 0.2300\n",
      "Epoch 494/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.1476 - mean_absolute_error: 0.2089\n",
      "Epoch 495/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.1337 - mean_absolute_error: 0.2117\n",
      "Epoch 496/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.2713 - mean_absolute_error: 0.2684\n",
      "Epoch 497/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.7359 - mean_absolute_error: 0.3805\n",
      "Epoch 498/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.6650 - mean_absolute_error: 0.5980\n",
      "Epoch 499/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.4195 - mean_absolute_error: 0.4245\n",
      "Epoch 500/500\n",
      "579/579 [==============================] - 0s 123us/step - loss: 0.4242 - mean_absolute_error: 0.3015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9d49d8780>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=56, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam' , metrics = ['mae'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs = 500, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 256us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2228.917835282642, 4.809386691020936]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Deep Learning Regression with PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets do PCA ### It is done after preprocessing and split of data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "(pca.n_components_)\n",
    "# obviously Y_train and Y_test will remain the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "579/579 [==============================] - 0s 580us/step - loss: 368.0859 - mean_absolute_error: 6.0770\n",
      "Epoch 2/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 365.8401 - mean_absolute_error: 5.9554\n",
      "Epoch 3/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 356.3937 - mean_absolute_error: 5.7118\n",
      "Epoch 4/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 319.8322 - mean_absolute_error: 5.4171\n",
      "Epoch 5/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 247.0023 - mean_absolute_error: 5.1543\n",
      "Epoch 6/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 181.5483 - mean_absolute_error: 5.1763\n",
      "Epoch 7/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 129.5417 - mean_absolute_error: 4.2748\n",
      "Epoch 8/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 104.0905 - mean_absolute_error: 3.5044\n",
      "Epoch 9/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 89.0006 - mean_absolute_error: 2.7684\n",
      "Epoch 10/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 84.0509 - mean_absolute_error: 2.8881\n",
      "Epoch 11/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 78.0865 - mean_absolute_error: 2.5795\n",
      "Epoch 12/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 72.3743 - mean_absolute_error: 2.4076\n",
      "Epoch 13/500\n",
      "579/579 [==============================] - 0s 89us/step - loss: 69.9075 - mean_absolute_error: 2.4096\n",
      "Epoch 14/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 69.5945 - mean_absolute_error: 2.3225\n",
      "Epoch 15/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 64.3086 - mean_absolute_error: 2.2199\n",
      "Epoch 16/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 63.7375 - mean_absolute_error: 2.1921\n",
      "Epoch 17/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 60.7983 - mean_absolute_error: 2.1464\n",
      "Epoch 18/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 61.9167 - mean_absolute_error: 2.1665\n",
      "Epoch 19/500\n",
      "579/579 [==============================] - 0s 75us/step - loss: 57.5436 - mean_absolute_error: 2.1923\n",
      "Epoch 20/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 54.3222 - mean_absolute_error: 2.0898\n",
      "Epoch 21/500\n",
      "579/579 [==============================] - 0s 125us/step - loss: 55.1717 - mean_absolute_error: 2.1518\n",
      "Epoch 22/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 51.7279 - mean_absolute_error: 2.0719\n",
      "Epoch 23/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 49.6079 - mean_absolute_error: 2.0109\n",
      "Epoch 24/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 49.2714 - mean_absolute_error: 2.0519\n",
      "Epoch 25/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 46.3801 - mean_absolute_error: 1.9712\n",
      "Epoch 26/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 46.2631 - mean_absolute_error: 1.9846\n",
      "Epoch 27/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 45.3843 - mean_absolute_error: 2.0822\n",
      "Epoch 28/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 40.7847 - mean_absolute_error: 1.9482\n",
      "Epoch 29/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 40.9584 - mean_absolute_error: 1.8957\n",
      "Epoch 30/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 43.0228 - mean_absolute_error: 2.0058\n",
      "Epoch 31/500\n",
      "579/579 [==============================] - 0s 117us/step - loss: 38.0983 - mean_absolute_error: 1.8995\n",
      "Epoch 32/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 37.4594 - mean_absolute_error: 1.9435\n",
      "Epoch 33/500\n",
      "579/579 [==============================] - 0s 120us/step - loss: 36.1878 - mean_absolute_error: 1.8560\n",
      "Epoch 34/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 34.3534 - mean_absolute_error: 1.8704\n",
      "Epoch 35/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 34.3160 - mean_absolute_error: 1.8401\n",
      "Epoch 36/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 30.9285 - mean_absolute_error: 1.7834\n",
      "Epoch 37/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 29.3416 - mean_absolute_error: 1.7704\n",
      "Epoch 38/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 28.8359 - mean_absolute_error: 1.7387\n",
      "Epoch 39/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 27.0284 - mean_absolute_error: 1.7238\n",
      "Epoch 40/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 24.9753 - mean_absolute_error: 1.6359\n",
      "Epoch 41/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 25.0718 - mean_absolute_error: 1.6852\n",
      "Epoch 42/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 23.9453 - mean_absolute_error: 1.6350\n",
      "Epoch 43/500\n",
      "579/579 [==============================] - 0s 133us/step - loss: 21.8403 - mean_absolute_error: 1.5752\n",
      "Epoch 44/500\n",
      "579/579 [==============================] - 0s 134us/step - loss: 19.5776 - mean_absolute_error: 1.5185\n",
      "Epoch 45/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 20.0917 - mean_absolute_error: 1.5646\n",
      "Epoch 46/500\n",
      "579/579 [==============================] - 0s 119us/step - loss: 18.4410 - mean_absolute_error: 1.5175\n",
      "Epoch 47/500\n",
      "579/579 [==============================] - 0s 114us/step - loss: 17.8353 - mean_absolute_error: 1.4581\n",
      "Epoch 48/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 18.2169 - mean_absolute_error: 1.4786\n",
      "Epoch 49/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 15.9923 - mean_absolute_error: 1.4548\n",
      "Epoch 50/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 15.2011 - mean_absolute_error: 1.3984\n",
      "Epoch 51/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 14.1887 - mean_absolute_error: 1.3841\n",
      "Epoch 52/500\n",
      "579/579 [==============================] - 0s 114us/step - loss: 13.4558 - mean_absolute_error: 1.3722\n",
      "Epoch 53/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 13.1888 - mean_absolute_error: 1.3916\n",
      "Epoch 54/500\n",
      "579/579 [==============================] - 0s 119us/step - loss: 12.5430 - mean_absolute_error: 1.3782\n",
      "Epoch 55/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 11.5562 - mean_absolute_error: 1.3154\n",
      "Epoch 56/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 11.3362 - mean_absolute_error: 1.3186\n",
      "Epoch 57/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 10.5362 - mean_absolute_error: 1.2920\n",
      "Epoch 58/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 9.9207 - mean_absolute_error: 1.2634\n",
      "Epoch 59/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 9.8065 - mean_absolute_error: 1.2705\n",
      "Epoch 60/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 9.4375 - mean_absolute_error: 1.2488\n",
      "Epoch 61/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 8.8632 - mean_absolute_error: 1.2662\n",
      "Epoch 62/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 8.2604 - mean_absolute_error: 1.1948\n",
      "Epoch 63/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 7.8103 - mean_absolute_error: 1.2033\n",
      "Epoch 64/500\n",
      "579/579 [==============================] - 0s 73us/step - loss: 8.0109 - mean_absolute_error: 1.2049\n",
      "Epoch 65/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 7.5594 - mean_absolute_error: 1.1666\n",
      "Epoch 66/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 7.1050 - mean_absolute_error: 1.1771\n",
      "Epoch 67/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 6.6762 - mean_absolute_error: 1.1444\n",
      "Epoch 68/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 6.6371 - mean_absolute_error: 1.1252\n",
      "Epoch 69/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 6.2363 - mean_absolute_error: 1.1223\n",
      "Epoch 70/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 6.0448 - mean_absolute_error: 1.1038\n",
      "Epoch 71/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 6.2414 - mean_absolute_error: 1.1074\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 96us/step - loss: 5.8467 - mean_absolute_error: 1.1006\n",
      "Epoch 73/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 5.7921 - mean_absolute_error: 1.0726\n",
      "Epoch 74/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 5.2193 - mean_absolute_error: 1.0684\n",
      "Epoch 75/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 5.5701 - mean_absolute_error: 1.0932\n",
      "Epoch 76/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 5.2053 - mean_absolute_error: 1.0583\n",
      "Epoch 77/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 4.9473 - mean_absolute_error: 1.0542\n",
      "Epoch 78/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 5.6501 - mean_absolute_error: 1.1102\n",
      "Epoch 79/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 5.0373 - mean_absolute_error: 1.0716\n",
      "Epoch 80/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 4.4704 - mean_absolute_error: 1.0296\n",
      "Epoch 81/500\n",
      "579/579 [==============================] - 0s 117us/step - loss: 4.4790 - mean_absolute_error: 1.0244\n",
      "Epoch 82/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 4.3088 - mean_absolute_error: 1.0106\n",
      "Epoch 83/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 4.5060 - mean_absolute_error: 1.0351\n",
      "Epoch 84/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 4.2867 - mean_absolute_error: 1.0295\n",
      "Epoch 85/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 4.1740 - mean_absolute_error: 1.0283\n",
      "Epoch 86/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 4.0990 - mean_absolute_error: 1.0004\n",
      "Epoch 87/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 4.0918 - mean_absolute_error: 0.9970\n",
      "Epoch 88/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 4.0379 - mean_absolute_error: 1.0173\n",
      "Epoch 89/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 4.0060 - mean_absolute_error: 1.0087\n",
      "Epoch 90/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 3.8028 - mean_absolute_error: 0.9810\n",
      "Epoch 91/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 3.5626 - mean_absolute_error: 0.9558\n",
      "Epoch 92/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 3.6501 - mean_absolute_error: 0.9614\n",
      "Epoch 93/500\n",
      "579/579 [==============================] - 0s 101us/step - loss: 3.6807 - mean_absolute_error: 0.9852\n",
      "Epoch 94/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 3.7586 - mean_absolute_error: 0.9949\n",
      "Epoch 95/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 3.7241 - mean_absolute_error: 0.9864\n",
      "Epoch 96/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 3.3765 - mean_absolute_error: 0.9532\n",
      "Epoch 97/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 3.3589 - mean_absolute_error: 0.9623\n",
      "Epoch 98/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 3.3874 - mean_absolute_error: 0.9602\n",
      "Epoch 99/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 3.4163 - mean_absolute_error: 0.9579\n",
      "Epoch 100/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 3.3448 - mean_absolute_error: 0.9393\n",
      "Epoch 101/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 3.3445 - mean_absolute_error: 0.9776\n",
      "Epoch 102/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 3.5607 - mean_absolute_error: 0.9881\n",
      "Epoch 103/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 3.5377 - mean_absolute_error: 0.9667\n",
      "Epoch 104/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 3.4084 - mean_absolute_error: 0.9603\n",
      "Epoch 105/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 3.2117 - mean_absolute_error: 0.9509\n",
      "Epoch 106/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 3.5686 - mean_absolute_error: 0.9989\n",
      "Epoch 107/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 2.9329 - mean_absolute_error: 0.9271\n",
      "Epoch 108/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 2.9302 - mean_absolute_error: 0.9138\n",
      "Epoch 109/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 2.8716 - mean_absolute_error: 0.9043\n",
      "Epoch 110/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 2.7835 - mean_absolute_error: 0.9002\n",
      "Epoch 111/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 2.6904 - mean_absolute_error: 0.8956\n",
      "Epoch 112/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.6975 - mean_absolute_error: 0.8962\n",
      "Epoch 113/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.7135 - mean_absolute_error: 0.8945\n",
      "Epoch 114/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.8186 - mean_absolute_error: 0.9194\n",
      "Epoch 115/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 2.7733 - mean_absolute_error: 0.9114\n",
      "Epoch 116/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.5360 - mean_absolute_error: 0.8839\n",
      "Epoch 117/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 2.3750 - mean_absolute_error: 0.8482\n",
      "Epoch 118/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.4609 - mean_absolute_error: 0.8593\n",
      "Epoch 119/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.3583 - mean_absolute_error: 0.8535\n",
      "Epoch 120/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.3707 - mean_absolute_error: 0.8688\n",
      "Epoch 121/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 2.3373 - mean_absolute_error: 0.8540\n",
      "Epoch 122/500\n",
      "579/579 [==============================] - 0s 99us/step - loss: 2.3946 - mean_absolute_error: 0.8669\n",
      "Epoch 123/500\n",
      "579/579 [==============================] - 0s 73us/step - loss: 2.4633 - mean_absolute_error: 0.8715\n",
      "Epoch 124/500\n",
      "579/579 [==============================] - 0s 104us/step - loss: 2.3392 - mean_absolute_error: 0.8483\n",
      "Epoch 125/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 2.2889 - mean_absolute_error: 0.8376\n",
      "Epoch 126/500\n",
      "579/579 [==============================] - 0s 92us/step - loss: 2.9372 - mean_absolute_error: 0.9304\n",
      "Epoch 127/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 2.4078 - mean_absolute_error: 0.8556\n",
      "Epoch 128/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 2.2375 - mean_absolute_error: 0.8282\n",
      "Epoch 129/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.2041 - mean_absolute_error: 0.8227\n",
      "Epoch 130/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 2.3617 - mean_absolute_error: 0.8532\n",
      "Epoch 131/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.1978 - mean_absolute_error: 0.8234\n",
      "Epoch 132/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 2.0198 - mean_absolute_error: 0.8000\n",
      "Epoch 133/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.9744 - mean_absolute_error: 0.7858\n",
      "Epoch 134/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.9881 - mean_absolute_error: 0.7887\n",
      "Epoch 135/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.9628 - mean_absolute_error: 0.7878\n",
      "Epoch 136/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.9940 - mean_absolute_error: 0.7812\n",
      "Epoch 137/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.9072 - mean_absolute_error: 0.7649\n",
      "Epoch 138/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.8806 - mean_absolute_error: 0.7644\n",
      "Epoch 139/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 1.9398 - mean_absolute_error: 0.7720\n",
      "Epoch 140/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.8367 - mean_absolute_error: 0.7681\n",
      "Epoch 141/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.9176 - mean_absolute_error: 0.7754\n",
      "Epoch 142/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.8654 - mean_absolute_error: 0.7647\n",
      "Epoch 143/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.9046 - mean_absolute_error: 0.7674\n",
      "Epoch 144/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.7621 - mean_absolute_error: 0.7640\n",
      "Epoch 145/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.6966 - mean_absolute_error: 0.7322\n",
      "Epoch 146/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 2.1163 - mean_absolute_error: 0.7780\n",
      "Epoch 147/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.5477 - mean_absolute_error: 0.8563\n",
      "Epoch 148/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 2.2170 - mean_absolute_error: 0.8165\n",
      "Epoch 149/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 2.4960 - mean_absolute_error: 0.8294\n",
      "Epoch 150/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 2.0998 - mean_absolute_error: 0.8062\n",
      "Epoch 151/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 2.1016 - mean_absolute_error: 0.7822\n",
      "Epoch 152/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.8917 - mean_absolute_error: 0.7552\n",
      "Epoch 153/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.7850 - mean_absolute_error: 0.7515\n",
      "Epoch 154/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.8418 - mean_absolute_error: 0.7463\n",
      "Epoch 155/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.7649 - mean_absolute_error: 0.7294\n",
      "Epoch 156/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.6352 - mean_absolute_error: 0.7223\n",
      "Epoch 157/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.5749 - mean_absolute_error: 0.7142\n",
      "Epoch 158/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.4871 - mean_absolute_error: 0.6932\n",
      "Epoch 159/500\n",
      "579/579 [==============================] - 0s 72us/step - loss: 1.5053 - mean_absolute_error: 0.6960\n",
      "Epoch 160/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 1.5524 - mean_absolute_error: 0.7043\n",
      "Epoch 161/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 1.8079 - mean_absolute_error: 0.7418\n",
      "Epoch 162/500\n",
      "579/579 [==============================] - 0s 126us/step - loss: 1.5970 - mean_absolute_error: 0.7224\n",
      "Epoch 163/500\n",
      "579/579 [==============================] - 0s 131us/step - loss: 1.6565 - mean_absolute_error: 0.7051\n",
      "Epoch 164/500\n",
      "579/579 [==============================] - 0s 138us/step - loss: 1.3238 - mean_absolute_error: 0.6724\n",
      "Epoch 165/500\n",
      "579/579 [==============================] - 0s 117us/step - loss: 1.5852 - mean_absolute_error: 0.7088\n",
      "Epoch 166/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 1.6348 - mean_absolute_error: 0.7182\n",
      "Epoch 167/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.3584 - mean_absolute_error: 0.6628\n",
      "Epoch 168/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.4194 - mean_absolute_error: 0.6866\n",
      "Epoch 169/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.4995 - mean_absolute_error: 0.6694\n",
      "Epoch 170/500\n",
      "579/579 [==============================] - 0s 72us/step - loss: 1.4543 - mean_absolute_error: 0.6755\n",
      "Epoch 171/500\n",
      "579/579 [==============================] - 0s 106us/step - loss: 2.1827 - mean_absolute_error: 0.7467\n",
      "Epoch 172/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 2.1133 - mean_absolute_error: 0.7450\n",
      "Epoch 173/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.8539 - mean_absolute_error: 0.7137\n",
      "Epoch 174/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.6919 - mean_absolute_error: 0.7020\n",
      "Epoch 175/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 1.5803 - mean_absolute_error: 0.6982\n",
      "Epoch 176/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.8265 - mean_absolute_error: 0.7003\n",
      "Epoch 177/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.9399 - mean_absolute_error: 0.7120\n",
      "Epoch 178/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.5401 - mean_absolute_error: 0.6655\n",
      "Epoch 179/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.1891 - mean_absolute_error: 0.6284\n",
      "Epoch 180/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.1489 - mean_absolute_error: 0.6196\n",
      "Epoch 181/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.0776 - mean_absolute_error: 0.6111\n",
      "Epoch 182/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.0671 - mean_absolute_error: 0.6039\n",
      "Epoch 183/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.0907 - mean_absolute_error: 0.6029\n",
      "Epoch 184/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 1.4680 - mean_absolute_error: 0.6617\n",
      "Epoch 185/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.1192 - mean_absolute_error: 0.6123\n",
      "Epoch 186/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.0947 - mean_absolute_error: 0.6104\n",
      "Epoch 187/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.0811 - mean_absolute_error: 0.6013\n",
      "Epoch 188/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.0421 - mean_absolute_error: 0.5980\n",
      "Epoch 189/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 1.0057 - mean_absolute_error: 0.5849\n",
      "Epoch 190/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.0721 - mean_absolute_error: 0.5936\n",
      "Epoch 191/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.1409 - mean_absolute_error: 0.6031\n",
      "Epoch 192/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.0136 - mean_absolute_error: 0.5894\n",
      "Epoch 193/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.1415 - mean_absolute_error: 0.5981\n",
      "Epoch 194/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.1701 - mean_absolute_error: 0.6130\n",
      "Epoch 195/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 1.4019 - mean_absolute_error: 0.6424\n",
      "Epoch 196/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.3691 - mean_absolute_error: 0.6391\n",
      "Epoch 197/500\n",
      "579/579 [==============================] - 0s 97us/step - loss: 1.8723 - mean_absolute_error: 0.6779\n",
      "Epoch 198/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 2.8682 - mean_absolute_error: 0.7526\n",
      "Epoch 199/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.3950 - mean_absolute_error: 0.6222\n",
      "Epoch 200/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 1.3454 - mean_absolute_error: 0.6112\n",
      "Epoch 201/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 1.4867 - mean_absolute_error: 0.6310\n",
      "Epoch 202/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.2989 - mean_absolute_error: 0.6061\n",
      "Epoch 203/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 1.0772 - mean_absolute_error: 0.5933\n",
      "Epoch 204/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.9632 - mean_absolute_error: 0.5673\n",
      "Epoch 205/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.0695 - mean_absolute_error: 0.5756\n",
      "Epoch 206/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 1.1198 - mean_absolute_error: 0.5749\n",
      "Epoch 207/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.8698 - mean_absolute_error: 0.5426\n",
      "Epoch 208/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.8887 - mean_absolute_error: 0.5373\n",
      "Epoch 209/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.8668 - mean_absolute_error: 0.5343\n",
      "Epoch 210/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8197 - mean_absolute_error: 0.5234\n",
      "Epoch 211/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7976 - mean_absolute_error: 0.5206\n",
      "Epoch 212/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.9194 - mean_absolute_error: 0.5428\n",
      "Epoch 213/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.9158 - mean_absolute_error: 0.5432\n",
      "Epoch 214/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 100us/step - loss: 0.8709 - mean_absolute_error: 0.5267\n",
      "Epoch 215/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.9635 - mean_absolute_error: 0.5404\n",
      "Epoch 216/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.4138 - mean_absolute_error: 0.6348\n",
      "Epoch 217/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.9127 - mean_absolute_error: 0.6620\n",
      "Epoch 218/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.5643 - mean_absolute_error: 0.6218\n",
      "Epoch 219/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 2.1423 - mean_absolute_error: 0.6661\n",
      "Epoch 220/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.3069 - mean_absolute_error: 0.5974\n",
      "Epoch 221/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.3891 - mean_absolute_error: 0.5888\n",
      "Epoch 222/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.0752 - mean_absolute_error: 0.5650\n",
      "Epoch 223/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.1852 - mean_absolute_error: 0.5798\n",
      "Epoch 224/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.2889 - mean_absolute_error: 0.6027\n",
      "Epoch 225/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.3013 - mean_absolute_error: 0.5932\n",
      "Epoch 226/500\n",
      "579/579 [==============================] - ETA: 0s - loss: 1.3175 - mean_absolute_error: 0.594 - 0s 85us/step - loss: 1.2952 - mean_absolute_error: 0.5493\n",
      "Epoch 227/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.0249 - mean_absolute_error: 0.5353\n",
      "Epoch 228/500\n",
      "579/579 [==============================] - 0s 157us/step - loss: 0.8564 - mean_absolute_error: 0.5169\n",
      "Epoch 229/500\n",
      "579/579 [==============================] - 0s 136us/step - loss: 0.9914 - mean_absolute_error: 0.5230\n",
      "Epoch 230/500\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.8020 - mean_absolute_error: 0.4920\n",
      "Epoch 231/500\n",
      "579/579 [==============================] - 0s 68us/step - loss: 0.8760 - mean_absolute_error: 0.5128\n",
      "Epoch 232/500\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.9102 - mean_absolute_error: 0.5164\n",
      "Epoch 233/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.8565 - mean_absolute_error: 0.5206\n",
      "Epoch 234/500\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.6963 - mean_absolute_error: 0.4837\n",
      "Epoch 235/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.7611 - mean_absolute_error: 0.4906\n",
      "Epoch 236/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.7311 - mean_absolute_error: 0.4742\n",
      "Epoch 237/500\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.8333 - mean_absolute_error: 0.5039\n",
      "Epoch 238/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 1.0995 - mean_absolute_error: 0.5391\n",
      "Epoch 239/500\n",
      "579/579 [==============================] - 0s 113us/step - loss: 1.1329 - mean_absolute_error: 0.5386\n",
      "Epoch 240/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 1.3758 - mean_absolute_error: 0.5876\n",
      "Epoch 241/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.2817 - mean_absolute_error: 0.5742\n",
      "Epoch 242/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.9269 - mean_absolute_error: 0.5305\n",
      "Epoch 243/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 1.1218 - mean_absolute_error: 0.5318\n",
      "Epoch 244/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 1.6881 - mean_absolute_error: 0.6467\n",
      "Epoch 245/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.0271 - mean_absolute_error: 0.5366\n",
      "Epoch 246/500\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.8848 - mean_absolute_error: 0.4997\n",
      "Epoch 247/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.8737 - mean_absolute_error: 0.5145\n",
      "Epoch 248/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7678 - mean_absolute_error: 0.4890\n",
      "Epoch 249/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.9472 - mean_absolute_error: 0.5199\n",
      "Epoch 250/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.8909 - mean_absolute_error: 0.5192\n",
      "Epoch 251/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.8348 - mean_absolute_error: 0.4978\n",
      "Epoch 252/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.6715 - mean_absolute_error: 0.4702\n",
      "Epoch 253/500\n",
      "579/579 [==============================] - 0s 116us/step - loss: 0.6515 - mean_absolute_error: 0.4614\n",
      "Epoch 254/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.6221 - mean_absolute_error: 0.4519\n",
      "Epoch 255/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.7225 - mean_absolute_error: 0.4810\n",
      "Epoch 256/500\n",
      "579/579 [==============================] - 0s 104us/step - loss: 0.8223 - mean_absolute_error: 0.4960\n",
      "Epoch 257/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.8186 - mean_absolute_error: 0.4753\n",
      "Epoch 258/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.6089 - mean_absolute_error: 0.4552\n",
      "Epoch 259/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.6310 - mean_absolute_error: 0.4549\n",
      "Epoch 260/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.6551 - mean_absolute_error: 0.4637\n",
      "Epoch 261/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.7046 - mean_absolute_error: 0.4730\n",
      "Epoch 262/500\n",
      "579/579 [==============================] - 0s 68us/step - loss: 0.7136 - mean_absolute_error: 0.4828\n",
      "Epoch 263/500\n",
      "579/579 [==============================] - 0s 120us/step - loss: 0.8716 - mean_absolute_error: 0.5026\n",
      "Epoch 264/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.8493 - mean_absolute_error: 0.5079\n",
      "Epoch 265/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9649 - mean_absolute_error: 0.5261\n",
      "Epoch 266/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.8761 - mean_absolute_error: 0.5030\n",
      "Epoch 267/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.4509 - mean_absolute_error: 0.6082\n",
      "Epoch 268/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 1.3751 - mean_absolute_error: 0.5879\n",
      "Epoch 269/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8346 - mean_absolute_error: 0.5000\n",
      "Epoch 270/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 1.2654 - mean_absolute_error: 0.5572\n",
      "Epoch 271/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 1.7398 - mean_absolute_error: 0.6524\n",
      "Epoch 272/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 3.7588 - mean_absolute_error: 0.7551\n",
      "Epoch 273/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.9038 - mean_absolute_error: 0.6254\n",
      "Epoch 274/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.5388 - mean_absolute_error: 0.5845\n",
      "Epoch 275/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.9730 - mean_absolute_error: 0.5009\n",
      "Epoch 276/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.6279 - mean_absolute_error: 0.4457\n",
      "Epoch 277/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.5862 - mean_absolute_error: 0.4398\n",
      "Epoch 278/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.5942 - mean_absolute_error: 0.4362\n",
      "Epoch 279/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.6109 - mean_absolute_error: 0.4365\n",
      "Epoch 280/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.6337 - mean_absolute_error: 0.4468\n",
      "Epoch 281/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6175 - mean_absolute_error: 0.4431\n",
      "Epoch 282/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.5806 - mean_absolute_error: 0.4216\n",
      "Epoch 283/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5818 - mean_absolute_error: 0.4334\n",
      "Epoch 284/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5601 - mean_absolute_error: 0.4270\n",
      "Epoch 285/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5490 - mean_absolute_error: 0.4193\n",
      "Epoch 286/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5365 - mean_absolute_error: 0.4198\n",
      "Epoch 287/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6384 - mean_absolute_error: 0.4416\n",
      "Epoch 288/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5542 - mean_absolute_error: 0.4287\n",
      "Epoch 289/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5940 - mean_absolute_error: 0.4233\n",
      "Epoch 290/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.5596 - mean_absolute_error: 0.4263\n",
      "Epoch 291/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.7276 - mean_absolute_error: 0.4725\n",
      "Epoch 292/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.9606 - mean_absolute_error: 0.5271\n",
      "Epoch 293/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7628 - mean_absolute_error: 0.4798\n",
      "Epoch 294/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7395 - mean_absolute_error: 0.4720\n",
      "Epoch 295/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.1413 - mean_absolute_error: 0.5252\n",
      "Epoch 296/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.1073 - mean_absolute_error: 0.5163\n",
      "Epoch 297/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.1622 - mean_absolute_error: 0.5184\n",
      "Epoch 298/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.8377 - mean_absolute_error: 0.4935\n",
      "Epoch 299/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6006 - mean_absolute_error: 0.4540\n",
      "Epoch 300/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.9496 - mean_absolute_error: 0.4682\n",
      "Epoch 301/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.5244 - mean_absolute_error: 0.5724\n",
      "Epoch 302/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.0787 - mean_absolute_error: 0.5198\n",
      "Epoch 303/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.9092 - mean_absolute_error: 0.4887\n",
      "Epoch 304/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.0441 - mean_absolute_error: 0.5384\n",
      "Epoch 305/500\n",
      "579/579 [==============================] - 0s 66us/step - loss: 1.2085 - mean_absolute_error: 0.5594\n",
      "Epoch 306/500\n",
      "579/579 [==============================] - 0s 110us/step - loss: 1.3064 - mean_absolute_error: 0.5428\n",
      "Epoch 307/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.9933 - mean_absolute_error: 0.5046\n",
      "Epoch 308/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.8015 - mean_absolute_error: 0.4757\n",
      "Epoch 309/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5992 - mean_absolute_error: 0.4373\n",
      "Epoch 310/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.6696 - mean_absolute_error: 0.4489\n",
      "Epoch 311/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5296 - mean_absolute_error: 0.4165\n",
      "Epoch 312/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5156 - mean_absolute_error: 0.4071\n",
      "Epoch 313/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.9054 - mean_absolute_error: 0.4636\n",
      "Epoch 314/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6028 - mean_absolute_error: 0.4378\n",
      "Epoch 315/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6846 - mean_absolute_error: 0.4510\n",
      "Epoch 316/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.1332 - mean_absolute_error: 0.4828\n",
      "Epoch 317/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.2064 - mean_absolute_error: 0.4871\n",
      "Epoch 318/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.2618 - mean_absolute_error: 0.5055\n",
      "Epoch 319/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7711 - mean_absolute_error: 0.4547\n",
      "Epoch 320/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6348 - mean_absolute_error: 0.4303\n",
      "Epoch 321/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.6007 - mean_absolute_error: 0.4286\n",
      "Epoch 322/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5594 - mean_absolute_error: 0.4162\n",
      "Epoch 323/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.5297 - mean_absolute_error: 0.4050\n",
      "Epoch 324/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.5642 - mean_absolute_error: 0.4177\n",
      "Epoch 325/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5484 - mean_absolute_error: 0.4155\n",
      "Epoch 326/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6218 - mean_absolute_error: 0.4359\n",
      "Epoch 327/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6460 - mean_absolute_error: 0.4428\n",
      "Epoch 328/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.6036 - mean_absolute_error: 0.4347\n",
      "Epoch 329/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5294 - mean_absolute_error: 0.4156\n",
      "Epoch 330/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6001 - mean_absolute_error: 0.4275\n",
      "Epoch 331/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 1.0018 - mean_absolute_error: 0.5120\n",
      "Epoch 332/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.0708 - mean_absolute_error: 0.5052\n",
      "Epoch 333/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.1487 - mean_absolute_error: 0.5228\n",
      "Epoch 334/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 1.1167 - mean_absolute_error: 0.5106\n",
      "Epoch 335/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9718 - mean_absolute_error: 0.4667\n",
      "Epoch 336/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6550 - mean_absolute_error: 0.4348\n",
      "Epoch 337/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.8096 - mean_absolute_error: 0.4559\n",
      "Epoch 338/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5344 - mean_absolute_error: 0.4199\n",
      "Epoch 339/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6625 - mean_absolute_error: 0.4420\n",
      "Epoch 340/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.4365 - mean_absolute_error: 0.5304\n",
      "Epoch 341/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 1.2139 - mean_absolute_error: 0.5194\n",
      "Epoch 342/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 1.3005 - mean_absolute_error: 0.5495\n",
      "Epoch 343/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.8572 - mean_absolute_error: 0.6112\n",
      "Epoch 344/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.2070 - mean_absolute_error: 0.5627\n",
      "Epoch 345/500\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.6280 - mean_absolute_error: 0.4461\n",
      "Epoch 346/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5380 - mean_absolute_error: 0.4107\n",
      "Epoch 347/500\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.5485 - mean_absolute_error: 0.4144\n",
      "Epoch 348/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5281 - mean_absolute_error: 0.4042\n",
      "Epoch 349/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6308 - mean_absolute_error: 0.4166\n",
      "Epoch 350/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4824 - mean_absolute_error: 0.3929\n",
      "Epoch 351/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4312 - mean_absolute_error: 0.3755\n",
      "Epoch 352/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5418 - mean_absolute_error: 0.4189\n",
      "Epoch 353/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4795 - mean_absolute_error: 0.3844\n",
      "Epoch 354/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6755 - mean_absolute_error: 0.4438\n",
      "Epoch 355/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 98us/step - loss: 0.7099 - mean_absolute_error: 0.4477\n",
      "Epoch 356/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.3500 - mean_absolute_error: 0.5247\n",
      "Epoch 357/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 1.2449 - mean_absolute_error: 0.5543\n",
      "Epoch 358/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.7977 - mean_absolute_error: 0.4690\n",
      "Epoch 359/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 1.0484 - mean_absolute_error: 0.4669\n",
      "Epoch 360/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.5433 - mean_absolute_error: 0.5966\n",
      "Epoch 361/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 1.4297 - mean_absolute_error: 0.5460\n",
      "Epoch 362/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.9957 - mean_absolute_error: 0.6397\n",
      "Epoch 363/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.3494 - mean_absolute_error: 0.5590\n",
      "Epoch 364/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.1922 - mean_absolute_error: 0.5388\n",
      "Epoch 365/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.9292 - mean_absolute_error: 0.4811\n",
      "Epoch 366/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.5135 - mean_absolute_error: 0.4096\n",
      "Epoch 367/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4831 - mean_absolute_error: 0.3951\n",
      "Epoch 368/500\n",
      "579/579 [==============================] - 0s 79us/step - loss: 0.5370 - mean_absolute_error: 0.4076\n",
      "Epoch 369/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4596 - mean_absolute_error: 0.3820\n",
      "Epoch 370/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4367 - mean_absolute_error: 0.3750\n",
      "Epoch 371/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4272 - mean_absolute_error: 0.3671\n",
      "Epoch 372/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4361 - mean_absolute_error: 0.3732\n",
      "Epoch 373/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4116 - mean_absolute_error: 0.3631\n",
      "Epoch 374/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.4085 - mean_absolute_error: 0.3630\n",
      "Epoch 375/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5101 - mean_absolute_error: 0.4029\n",
      "Epoch 376/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.5336 - mean_absolute_error: 0.4053\n",
      "Epoch 377/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4131 - mean_absolute_error: 0.3648\n",
      "Epoch 378/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4739 - mean_absolute_error: 0.3837\n",
      "Epoch 379/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4835 - mean_absolute_error: 0.3910\n",
      "Epoch 380/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5698 - mean_absolute_error: 0.4250\n",
      "Epoch 381/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.6006 - mean_absolute_error: 0.4276\n",
      "Epoch 382/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.8003 - mean_absolute_error: 0.4521\n",
      "Epoch 383/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5738 - mean_absolute_error: 0.4069\n",
      "Epoch 384/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.8027 - mean_absolute_error: 0.5211\n",
      "Epoch 385/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 2.1389 - mean_absolute_error: 0.6313\n",
      "Epoch 386/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7661 - mean_absolute_error: 0.4716\n",
      "Epoch 387/500\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.6877 - mean_absolute_error: 0.4541\n",
      "Epoch 388/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.6284 - mean_absolute_error: 0.4320\n",
      "Epoch 389/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.9517 - mean_absolute_error: 0.4838\n",
      "Epoch 390/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.5503 - mean_absolute_error: 0.4111\n",
      "Epoch 391/500\n",
      "579/579 [==============================] - 0s 74us/step - loss: 0.4756 - mean_absolute_error: 0.3872\n",
      "Epoch 392/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.5739 - mean_absolute_error: 0.4129\n",
      "Epoch 393/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 1.0386 - mean_absolute_error: 0.4795\n",
      "Epoch 394/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.8111 - mean_absolute_error: 0.4685\n",
      "Epoch 395/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6858 - mean_absolute_error: 0.4497\n",
      "Epoch 396/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8386 - mean_absolute_error: 0.4547\n",
      "Epoch 397/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.9276 - mean_absolute_error: 0.4449\n",
      "Epoch 398/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7693 - mean_absolute_error: 0.4390\n",
      "Epoch 399/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.5320 - mean_absolute_error: 0.4919\n",
      "Epoch 400/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.3954 - mean_absolute_error: 0.5551\n",
      "Epoch 401/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.9994 - mean_absolute_error: 0.5028\n",
      "Epoch 402/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8582 - mean_absolute_error: 0.4684\n",
      "Epoch 403/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.6400 - mean_absolute_error: 0.4276\n",
      "Epoch 404/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.8934 - mean_absolute_error: 0.4336\n",
      "Epoch 405/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4868 - mean_absolute_error: 0.3822\n",
      "Epoch 406/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4313 - mean_absolute_error: 0.3727\n",
      "Epoch 407/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4641 - mean_absolute_error: 0.3723\n",
      "Epoch 408/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.5310 - mean_absolute_error: 0.4008\n",
      "Epoch 409/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.5492 - mean_absolute_error: 0.3987\n",
      "Epoch 410/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.8924 - mean_absolute_error: 0.4615\n",
      "Epoch 411/500\n",
      "579/579 [==============================] - 0s 92us/step - loss: 0.7238 - mean_absolute_error: 0.4637\n",
      "Epoch 412/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.2027 - mean_absolute_error: 0.5247\n",
      "Epoch 413/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7571 - mean_absolute_error: 0.4654\n",
      "Epoch 414/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.6361 - mean_absolute_error: 0.4288\n",
      "Epoch 415/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4905 - mean_absolute_error: 0.3899\n",
      "Epoch 416/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4786 - mean_absolute_error: 0.3719\n",
      "Epoch 417/500\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.5988 - mean_absolute_error: 0.3996\n",
      "Epoch 418/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.5968 - mean_absolute_error: 0.3948\n",
      "Epoch 419/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.6898 - mean_absolute_error: 0.4338\n",
      "Epoch 420/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8036 - mean_absolute_error: 0.4632\n",
      "Epoch 421/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.5736 - mean_absolute_error: 0.4130\n",
      "Epoch 422/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.6652 - mean_absolute_error: 0.4053\n",
      "Epoch 423/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.5869 - mean_absolute_error: 0.4253\n",
      "Epoch 424/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6486 - mean_absolute_error: 0.4310\n",
      "Epoch 425/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.6828 - mean_absolute_error: 0.4244\n",
      "Epoch 426/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6874 - mean_absolute_error: 0.4339\n",
      "Epoch 427/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8876 - mean_absolute_error: 0.4812\n",
      "Epoch 428/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.0880 - mean_absolute_error: 0.4683\n",
      "Epoch 429/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.1217 - mean_absolute_error: 0.4741\n",
      "Epoch 430/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.9200 - mean_absolute_error: 0.4535\n",
      "Epoch 431/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.0619 - mean_absolute_error: 0.4827\n",
      "Epoch 432/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.3372 - mean_absolute_error: 0.5616\n",
      "Epoch 433/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.6200 - mean_absolute_error: 0.4347\n",
      "Epoch 434/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4867 - mean_absolute_error: 0.3907\n",
      "Epoch 435/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.4014 - mean_absolute_error: 0.3537\n",
      "Epoch 436/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.3790 - mean_absolute_error: 0.3414\n",
      "Epoch 437/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3836 - mean_absolute_error: 0.3423\n",
      "Epoch 438/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.4627 - mean_absolute_error: 0.3692\n",
      "Epoch 439/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.4398 - mean_absolute_error: 0.3671\n",
      "Epoch 440/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4849 - mean_absolute_error: 0.3758\n",
      "Epoch 441/500\n",
      "579/579 [==============================] - 0s 76us/step - loss: 0.6968 - mean_absolute_error: 0.4148\n",
      "Epoch 442/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 1.6428 - mean_absolute_error: 0.5406\n",
      "Epoch 443/500\n",
      "579/579 [==============================] - 0s 75us/step - loss: 0.7944 - mean_absolute_error: 0.4765\n",
      "Epoch 444/500\n",
      "579/579 [==============================] - 0s 96us/step - loss: 1.3078 - mean_absolute_error: 0.5062\n",
      "Epoch 445/500\n",
      "579/579 [==============================] - 0s 75us/step - loss: 0.8197 - mean_absolute_error: 0.4505\n",
      "Epoch 446/500\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.7867 - mean_absolute_error: 0.4405\n",
      "Epoch 447/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.6949 - mean_absolute_error: 0.4232\n",
      "Epoch 448/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5206 - mean_absolute_error: 0.3952\n",
      "Epoch 449/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.4734 - mean_absolute_error: 0.3802\n",
      "Epoch 450/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.4330 - mean_absolute_error: 0.3634\n",
      "Epoch 451/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.4260 - mean_absolute_error: 0.3613\n",
      "Epoch 452/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4274 - mean_absolute_error: 0.3595\n",
      "Epoch 453/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4294 - mean_absolute_error: 0.3528\n",
      "Epoch 454/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4494 - mean_absolute_error: 0.3605\n",
      "Epoch 455/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4579 - mean_absolute_error: 0.3609\n",
      "Epoch 456/500\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.5458 - mean_absolute_error: 0.3880\n",
      "Epoch 457/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.5092 - mean_absolute_error: 0.3998\n",
      "Epoch 458/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4922 - mean_absolute_error: 0.3859\n",
      "Epoch 459/500\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.6567 - mean_absolute_error: 0.4025\n",
      "Epoch 460/500\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.9589 - mean_absolute_error: 0.4898\n",
      "Epoch 461/500\n",
      "579/579 [==============================] - 0s 75us/step - loss: 1.0158 - mean_absolute_error: 0.4984\n",
      "Epoch 462/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.7775 - mean_absolute_error: 0.6135\n",
      "Epoch 463/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.5404 - mean_absolute_error: 0.5524\n",
      "Epoch 464/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.9095 - mean_absolute_error: 0.4798\n",
      "Epoch 465/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 1.2620 - mean_absolute_error: 0.4954\n",
      "Epoch 466/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.9343 - mean_absolute_error: 0.4865\n",
      "Epoch 467/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4601 - mean_absolute_error: 0.3767\n",
      "Epoch 468/500\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.4083 - mean_absolute_error: 0.3583\n",
      "Epoch 469/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.4278 - mean_absolute_error: 0.3695\n",
      "Epoch 470/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.4651 - mean_absolute_error: 0.3650\n",
      "Epoch 471/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.8759 - mean_absolute_error: 0.4631\n",
      "Epoch 472/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6057 - mean_absolute_error: 0.4203\n",
      "Epoch 473/500\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.5285 - mean_absolute_error: 0.3873\n",
      "Epoch 474/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4858 - mean_absolute_error: 0.3810\n",
      "Epoch 475/500\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.5675 - mean_absolute_error: 0.3989\n",
      "Epoch 476/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.5017 - mean_absolute_error: 0.3905\n",
      "Epoch 477/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.6713 - mean_absolute_error: 0.3844\n",
      "Epoch 478/500\n",
      "579/579 [==============================] - 0s 82us/step - loss: 0.6227 - mean_absolute_error: 0.4090\n",
      "Epoch 479/500\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.4874 - mean_absolute_error: 0.3832\n",
      "Epoch 480/500\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.4667 - mean_absolute_error: 0.3745\n",
      "Epoch 481/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.7421 - mean_absolute_error: 0.4156\n",
      "Epoch 482/500\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.6309 - mean_absolute_error: 0.4136\n",
      "Epoch 483/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.6177 - mean_absolute_error: 0.4270\n",
      "Epoch 484/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.4945 - mean_absolute_error: 0.3849\n",
      "Epoch 485/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4231 - mean_absolute_error: 0.3623\n",
      "Epoch 486/500\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.5697 - mean_absolute_error: 0.4100\n",
      "Epoch 487/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4702 - mean_absolute_error: 0.3733\n",
      "Epoch 488/500\n",
      "579/579 [==============================] - 0s 99us/step - loss: 0.5078 - mean_absolute_error: 0.3781\n",
      "Epoch 489/500\n",
      "579/579 [==============================] - 0s 91us/step - loss: 0.8987 - mean_absolute_error: 0.4656\n",
      "Epoch 490/500\n",
      "579/579 [==============================] - 0s 71us/step - loss: 1.3678 - mean_absolute_error: 0.4874\n",
      "Epoch 491/500\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.8182 - mean_absolute_error: 0.4196\n",
      "Epoch 492/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.7694 - mean_absolute_error: 0.4335\n",
      "Epoch 493/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 1.3969 - mean_absolute_error: 0.5167\n",
      "Epoch 494/500\n",
      "579/579 [==============================] - 0s 86us/step - loss: 1.3282 - mean_absolute_error: 0.4958\n",
      "Epoch 495/500\n",
      "579/579 [==============================] - 0s 95us/step - loss: 0.9613 - mean_absolute_error: 0.4801\n",
      "Epoch 496/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5345 - mean_absolute_error: 0.3995\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "579/579 [==============================] - 0s 88us/step - loss: 0.4930 - mean_absolute_error: 0.3772\n",
      "Epoch 498/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.3990 - mean_absolute_error: 0.3439\n",
      "Epoch 499/500\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.4015 - mean_absolute_error: 0.3481\n",
      "Epoch 500/500\n",
      "579/579 [==============================] - 0s 90us/step - loss: 0.5284 - mean_absolute_error: 0.3832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9d71906a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_dim=44, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='normal'))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam' , metrics = ['mae'])\n",
    "\n",
    "model.fit(X_train_reduced, y_train, epochs = 500, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 386us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2133.683125024994, 5.656076866941354]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_reduced, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  GET DATA READY FOR CLASSIFICATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "y= df['risk']\n",
    "X = df.drop(['audit_risk','risk'],axis =1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together \n",
    "X_test = scaler.transform(x_test_org)  \n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 56)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "579/579 [==============================] - 1s 1ms/step - loss: 0.6643 - acc: 0.6079\n",
      "Epoch 2/150\n",
      "579/579 [==============================] - 0s 104us/step - loss: 0.5634 - acc: 0.7427\n",
      "Epoch 3/150\n",
      "579/579 [==============================] - 0s 102us/step - loss: 0.4490 - acc: 0.8549\n",
      "Epoch 4/150\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.3109 - acc: 0.9136\n",
      "Epoch 5/150\n",
      "579/579 [==============================] - 0s 143us/step - loss: 0.2070 - acc: 0.9309\n",
      "Epoch 6/150\n",
      "579/579 [==============================] - 0s 137us/step - loss: 0.1564 - acc: 0.9465\n",
      "Epoch 7/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.1260 - acc: 0.9568\n",
      "Epoch 8/150\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.1007 - acc: 0.9672\n",
      "Epoch 9/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0811 - acc: 0.9724\n",
      "Epoch 10/150\n",
      "579/579 [==============================] - 0s 69us/step - loss: 0.0669 - acc: 0.9827\n",
      "Epoch 11/150\n",
      "579/579 [==============================] - 0s 137us/step - loss: 0.0554 - acc: 0.9845\n",
      "Epoch 12/150\n",
      "579/579 [==============================] - 0s 106us/step - loss: 0.0484 - acc: 0.9862\n",
      "Epoch 13/150\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.0429 - acc: 0.9845\n",
      "Epoch 14/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0378 - acc: 0.9879\n",
      "Epoch 15/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0353 - acc: 0.9914\n",
      "Epoch 16/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0319 - acc: 0.9862\n",
      "Epoch 17/150\n",
      "579/579 [==============================] - 0s 101us/step - loss: 0.0298 - acc: 0.9914\n",
      "Epoch 18/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0278 - acc: 0.9896\n",
      "Epoch 19/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0238 - acc: 0.9948\n",
      "Epoch 20/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0230 - acc: 0.9914\n",
      "Epoch 21/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0211 - acc: 0.9965\n",
      "Epoch 22/150\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.0188 - acc: 0.9965\n",
      "Epoch 23/150\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.0180 - acc: 0.9948\n",
      "Epoch 24/150\n",
      "579/579 [==============================] - 0s 118us/step - loss: 0.0171 - acc: 0.9965\n",
      "Epoch 25/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0163 - acc: 0.9965\n",
      "Epoch 26/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0171 - acc: 0.9931\n",
      "Epoch 27/150\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.0151 - acc: 0.9965\n",
      "Epoch 28/150\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.0136 - acc: 0.9965\n",
      "Epoch 29/150\n",
      "579/579 [==============================] - 0s 137us/step - loss: 0.0127 - acc: 0.9965\n",
      "Epoch 30/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 31/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0121 - acc: 0.9948\n",
      "Epoch 32/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0107 - acc: 0.9965\n",
      "Epoch 33/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0103 - acc: 0.9965\n",
      "Epoch 34/150\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.0105 - acc: 0.9983\n",
      "Epoch 35/150\n",
      "579/579 [==============================] - 0s 141us/step - loss: 0.0097 - acc: 0.9983\n",
      "Epoch 36/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0097 - acc: 0.9965\n",
      "Epoch 37/150\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.0090 - acc: 0.9965\n",
      "Epoch 38/150\n",
      "579/579 [==============================] - 0s 142us/step - loss: 0.0084 - acc: 0.9983\n",
      "Epoch 39/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0071 - acc: 0.9983\n",
      "Epoch 40/150\n",
      "579/579 [==============================] - 0s 146us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 41/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 42/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 43/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 44/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0062 - acc: 0.9965\n",
      "Epoch 45/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 46/150\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.0061 - acc: 0.9983\n",
      "Epoch 47/150\n",
      "579/579 [==============================] - 0s 142us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 48/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 49/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 50/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0046 - acc: 0.9983\n",
      "Epoch 51/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 52/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 53/150\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.0058 - acc: 0.9965\n",
      "Epoch 54/150\n",
      "579/579 [==============================] - 0s 143us/step - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 55/150\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 56/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 57/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 58/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 59/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 60/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 0.0045 - acc: 0.9983\n",
      "Epoch 61/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0034 - acc: 0.9983\n",
      "Epoch 62/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 63/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 64/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 65/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 66/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 67/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 68/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 69/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 70/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 71/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 72/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 73/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 74/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 75/150\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 76/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 77/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 78/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 79/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 9.7185e-04 - acc: 1.0000\n",
      "Epoch 80/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 81/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 8.8430e-04 - acc: 1.0000\n",
      "Epoch 82/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0022 - acc: 0.9983\n",
      "Epoch 83/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 84/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 85/150\n",
      "579/579 [==============================] - 0s 104us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 86/150\n",
      "579/579 [==============================] - 0s 107us/step - loss: 9.3619e-04 - acc: 1.0000\n",
      "Epoch 87/150\n",
      "579/579 [==============================] - 0s 103us/step - loss: 7.2686e-04 - acc: 1.0000\n",
      "Epoch 88/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 6.1880e-04 - acc: 1.0000\n",
      "Epoch 89/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 5.6674e-04 - acc: 1.0000\n",
      "Epoch 90/150\n",
      "579/579 [==============================] - 0s 100us/step - loss: 6.6347e-04 - acc: 1.0000\n",
      "Epoch 91/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 5.6268e-04 - acc: 1.0000\n",
      "Epoch 92/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 5.3619e-04 - acc: 1.0000\n",
      "Epoch 93/150\n",
      "579/579 [==============================] - 0s 73us/step - loss: 5.1393e-04 - acc: 1.0000\n",
      "Epoch 94/150\n",
      "579/579 [==============================] - 0s 131us/step - loss: 5.1030e-04 - acc: 1.0000\n",
      "Epoch 95/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 4.4605e-04 - acc: 1.0000\n",
      "Epoch 96/150\n",
      "579/579 [==============================] - 0s 104us/step - loss: 4.7508e-04 - acc: 1.0000\n",
      "Epoch 97/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 4.8936e-04 - acc: 1.0000\n",
      "Epoch 98/150\n",
      "579/579 [==============================] - 0s 113us/step - loss: 5.0952e-04 - acc: 1.0000\n",
      "Epoch 99/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 4.3725e-04 - acc: 1.0000\n",
      "Epoch 100/150\n",
      "579/579 [==============================] - 0s 95us/step - loss: 4.3956e-04 - acc: 1.0000\n",
      "Epoch 101/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 4.0398e-04 - acc: 1.0000\n",
      "Epoch 102/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 4.0945e-04 - acc: 1.0000\n",
      "Epoch 103/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 4.8817e-04 - acc: 1.0000\n",
      "Epoch 104/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 3.1472e-04 - acc: 1.0000\n",
      "Epoch 105/150\n",
      "579/579 [==============================] - 0s 131us/step - loss: 3.7668e-04 - acc: 1.0000\n",
      "Epoch 106/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 3.3287e-04 - acc: 1.0000\n",
      "Epoch 107/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 2.6966e-04 - acc: 1.0000\n",
      "Epoch 108/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 3.2202e-04 - acc: 1.0000\n",
      "Epoch 109/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 3.6970e-04 - acc: 1.0000\n",
      "Epoch 110/150\n",
      "579/579 [==============================] - 0s 107us/step - loss: 4.7269e-04 - acc: 1.0000\n",
      "Epoch 111/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0079 - acc: 0.9983\n",
      "Epoch 112/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0042 - acc: 0.9965\n",
      "Epoch 113/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0141 - acc: 0.9914\n",
      "Epoch 114/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0052 - acc: 0.9965\n",
      "Epoch 115/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 116/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0022 - acc: 0.9983\n",
      "Epoch 117/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0056 - acc: 0.9948\n",
      "Epoch 118/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 5.4830e-04 - acc: 1.0000\n",
      "Epoch 119/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 2.3149e-04 - acc: 1.0000\n",
      "Epoch 120/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 2.1362e-04 - acc: 1.0000\n",
      "Epoch 121/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 2.1325e-04 - acc: 1.0000\n",
      "Epoch 122/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 2.0650e-04 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 2.0034e-04 - acc: 1.0000 0s - loss: 1.9530e-04 - acc: 1.000\n",
      "Epoch 124/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 1.8988e-04 - acc: 1.0000\n",
      "Epoch 125/150\n",
      "579/579 [==============================] - 0s 85us/step - loss: 1.8924e-04 - acc: 1.0000\n",
      "Epoch 126/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 1.8303e-04 - acc: 1.0000\n",
      "Epoch 127/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 1.7832e-04 - acc: 1.0000\n",
      "Epoch 128/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 1.7818e-04 - acc: 1.0000\n",
      "Epoch 129/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 1.7937e-04 - acc: 1.0000\n",
      "Epoch 130/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 1.6635e-04 - acc: 1.0000\n",
      "Epoch 131/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 1.6770e-04 - acc: 1.0000\n",
      "Epoch 132/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 1.6586e-04 - acc: 1.0000\n",
      "Epoch 133/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 1.6586e-04 - acc: 1.0000\n",
      "Epoch 134/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 1.6551e-04 - acc: 1.0000\n",
      "Epoch 135/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 1.4885e-04 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 1.5518e-04 - acc: 1.0000\n",
      "Epoch 137/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 1.4882e-04 - acc: 1.0000\n",
      "Epoch 138/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 1.5205e-04 - acc: 1.0000\n",
      "Epoch 139/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 1.3757e-04 - acc: 1.0000\n",
      "Epoch 140/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 1.3384e-04 - acc: 1.0000\n",
      "Epoch 141/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 1.3453e-04 - acc: 1.0000\n",
      "Epoch 142/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 1.3927e-04 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 1.3875e-04 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "579/579 [==============================] - 0s 107us/step - loss: 1.4093e-04 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 1.2144e-04 - acc: 1.0000\n",
      "Epoch 146/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 1.3021e-04 - acc: 1.0000\n",
      "Epoch 147/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 1.2713e-04 - acc: 1.0000\n",
      "Epoch 148/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 1.2348e-04 - acc: 1.0000\n",
      "Epoch 149/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 1.1376e-04 - acc: 1.0000\n",
      "Epoch 150/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 1.1357e-04 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9d764ab38>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=56, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 640us/step\n",
      "\n",
      "acc: 95.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Deep Learning Classification with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Lets do PCA ### It is done after preprocessing and split of data\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.95)\n",
    "\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "X_test_reduced = pca.transform(X_test)\n",
    "\n",
    "(pca.n_components_)\n",
    "# obviously Y_train and Y_test will remain the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "579/579 [==============================] - 0s 810us/step - loss: 0.6734 - acc: 0.6010\n",
      "Epoch 2/150\n",
      "579/579 [==============================] - 0s 108us/step - loss: 0.6188 - acc: 0.8048\n",
      "Epoch 3/150\n",
      "579/579 [==============================] - 0s 73us/step - loss: 0.5447 - acc: 0.8946\n",
      "Epoch 4/150\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.4629 - acc: 0.9206\n",
      "Epoch 5/150\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.3631 - acc: 0.9413\n",
      "Epoch 6/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.2591 - acc: 0.9534\n",
      "Epoch 7/150\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.1851 - acc: 0.9534\n",
      "Epoch 8/150\n",
      "579/579 [==============================] - 0s 84us/step - loss: 0.1415 - acc: 0.9568\n",
      "Epoch 9/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 0.1143 - acc: 0.9655\n",
      "Epoch 10/150\n",
      "579/579 [==============================] - 0s 116us/step - loss: 0.0957 - acc: 0.9775\n",
      "Epoch 11/150\n",
      "579/579 [==============================] - 0s 93us/step - loss: 0.0801 - acc: 0.9741\n",
      "Epoch 12/150\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.0693 - acc: 0.9793\n",
      "Epoch 13/150\n",
      "579/579 [==============================] - 0s 132us/step - loss: 0.0661 - acc: 0.9775\n",
      "Epoch 14/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0570 - acc: 0.9793\n",
      "Epoch 15/150\n",
      "579/579 [==============================] - 0s 96us/step - loss: 0.0508 - acc: 0.9879\n",
      "Epoch 16/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0470 - acc: 0.9879\n",
      "Epoch 17/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0413 - acc: 0.9914\n",
      "Epoch 18/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0376 - acc: 0.9931\n",
      "Epoch 19/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0352 - acc: 0.9948\n",
      "Epoch 20/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0317 - acc: 0.9948\n",
      "Epoch 21/150\n",
      "579/579 [==============================] - 0s 120us/step - loss: 0.0311 - acc: 0.9914\n",
      "Epoch 22/150\n",
      "579/579 [==============================] - 0s 131us/step - loss: 0.0279 - acc: 0.9965\n",
      "Epoch 23/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0258 - acc: 0.9948\n",
      "Epoch 24/150\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.0257 - acc: 0.9948\n",
      "Epoch 25/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0222 - acc: 0.9948\n",
      "Epoch 26/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0211 - acc: 0.9965\n",
      "Epoch 27/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0205 - acc: 0.9948\n",
      "Epoch 28/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0198 - acc: 0.9965\n",
      "Epoch 29/150\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.0191 - acc: 0.9931\n",
      "Epoch 30/150\n",
      "579/579 [==============================] - 0s 146us/step - loss: 0.0184 - acc: 0.9965\n",
      "Epoch 31/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0179 - acc: 0.9948\n",
      "Epoch 32/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0156 - acc: 0.9965\n",
      "Epoch 33/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0171 - acc: 0.9931\n",
      "Epoch 34/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0149 - acc: 0.9965\n",
      "Epoch 35/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0141 - acc: 0.9965\n",
      "Epoch 36/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0141 - acc: 0.9965\n",
      "Epoch 37/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0130 - acc: 0.9965\n",
      "Epoch 38/150\n",
      "579/579 [==============================] - 0s 140us/step - loss: 0.0132 - acc: 0.9931\n",
      "Epoch 39/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0115 - acc: 0.9965\n",
      "Epoch 40/150\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.0121 - acc: 0.9948\n",
      "Epoch 41/150\n",
      "579/579 [==============================] - 0s 141us/step - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 42/150\n",
      "579/579 [==============================] - 0s 85us/step - loss: 0.0102 - acc: 0.9983\n",
      "Epoch 43/150\n",
      "579/579 [==============================] - 0s 139us/step - loss: 0.0112 - acc: 0.9948\n",
      "Epoch 44/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0100 - acc: 0.9983\n",
      "Epoch 45/150\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.0095 - acc: 0.9965\n",
      "Epoch 46/150\n",
      "579/579 [==============================] - 0s 145us/step - loss: 0.0085 - acc: 0.9983\n",
      "Epoch 47/150\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.0086 - acc: 0.9965\n",
      "Epoch 48/150\n",
      "579/579 [==============================] - 0s 152us/step - loss: 0.0101 - acc: 0.9948\n",
      "Epoch 49/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0092 - acc: 0.9965\n",
      "Epoch 50/150\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.0106 - acc: 0.9965\n",
      "Epoch 51/150\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.0090 - acc: 0.9965\n",
      "Epoch 52/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0080 - acc: 0.9983\n",
      "Epoch 53/150\n",
      "579/579 [==============================] - 0s 140us/step - loss: 0.0068 - acc: 0.9983\n",
      "Epoch 54/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0064 - acc: 0.9983\n",
      "Epoch 55/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0064 - acc: 0.9983\n",
      "Epoch 56/150\n",
      "579/579 [==============================] - 0s 131us/step - loss: 0.0066 - acc: 0.9965\n",
      "Epoch 57/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0065 - acc: 0.9983\n",
      "Epoch 58/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0064 - acc: 0.9965\n",
      "Epoch 59/150\n",
      "579/579 [==============================] - 0s 106us/step - loss: 0.0073 - acc: 0.9983\n",
      "Epoch 60/150\n",
      "579/579 [==============================] - 0s 103us/step - loss: 0.0056 - acc: 0.9983\n",
      "Epoch 61/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 62/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0072 - acc: 0.9965\n",
      "Epoch 63/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0049 - acc: 0.9983\n",
      "Epoch 64/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0059 - acc: 0.9965\n",
      "Epoch 65/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0039 - acc: 0.9983\n",
      "Epoch 66/150\n",
      "579/579 [==============================] - 0s 126us/step - loss: 0.0045 - acc: 0.9983\n",
      "Epoch 67/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 68/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0059 - acc: 0.9983\n",
      "Epoch 69/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 70/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0046 - acc: 0.9983\n",
      "Epoch 71/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0068 - acc: 0.9965\n",
      "Epoch 72/150\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.0100 - acc: 0.9948\n",
      "Epoch 73/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 0.0070 - acc: 0.9965\n",
      "Epoch 74/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0081 - acc: 0.9965\n",
      "Epoch 75/150\n",
      "579/579 [==============================] - 0s 138us/step - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 76/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 77/150\n",
      "579/579 [==============================] - 0s 89us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 78/150\n",
      "579/579 [==============================] - 0s 150us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 79/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 80/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 81/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0051 - acc: 0.9965\n",
      "Epoch 82/150\n",
      "579/579 [==============================] - 0s 133us/step - loss: 0.0056 - acc: 0.9965\n",
      "Epoch 83/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0031 - acc: 0.9983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0060 - acc: 0.9965\n",
      "Epoch 85/150\n",
      "579/579 [==============================] - 0s 134us/step - loss: 0.0054 - acc: 0.9965\n",
      "Epoch 86/150\n",
      "579/579 [==============================] - 0s 127us/step - loss: 0.0053 - acc: 0.9965\n",
      "Epoch 87/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0043 - acc: 0.9983\n",
      "Epoch 88/150\n",
      "579/579 [==============================] - 0s 134us/step - loss: 0.0050 - acc: 0.9983\n",
      "Epoch 89/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 0.0069 - acc: 0.9948\n",
      "Epoch 90/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0076 - acc: 0.9948\n",
      "Epoch 91/150\n",
      "579/579 [==============================] - 0s 124us/step - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 92/150\n",
      "579/579 [==============================] - 0s 134us/step - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 93/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0052 - acc: 0.9965\n",
      "Epoch 94/150\n",
      "579/579 [==============================] - 0s 136us/step - loss: 0.0137 - acc: 0.9965\n",
      "Epoch 95/150\n",
      "579/579 [==============================] - 0s 214us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 96/150\n",
      "579/579 [==============================] - 0s 167us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 97/150\n",
      "579/579 [==============================] - 0s 134us/step - loss: 0.0027 - acc: 0.9983\n",
      "Epoch 98/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0029 - acc: 0.9983\n",
      "Epoch 99/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0036 - acc: 0.9983\n",
      "Epoch 100/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0056 - acc: 0.9965\n",
      "Epoch 101/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0045 - acc: 0.9983\n",
      "Epoch 102/150\n",
      "579/579 [==============================] - 0s 87us/step - loss: 0.0034 - acc: 0.9983\n",
      "Epoch 103/150\n",
      "579/579 [==============================] - 0s 129us/step - loss: 0.0025 - acc: 0.9983\n",
      "Epoch 104/150\n",
      "579/579 [==============================] - 0s 113us/step - loss: 0.0030 - acc: 0.9983\n",
      "Epoch 105/150\n",
      "579/579 [==============================] - 0s 98us/step - loss: 0.0022 - acc: 0.9983\n",
      "Epoch 106/150\n",
      "579/579 [==============================] - 0s 89us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 107/150\n",
      "579/579 [==============================] - 0s 132us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 108/150\n",
      "579/579 [==============================] - 0s 113us/step - loss: 0.0020 - acc: 0.9983\n",
      "Epoch 109/150\n",
      "579/579 [==============================] - 0s 94us/step - loss: 0.0048 - acc: 0.9965\n",
      "Epoch 110/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0035 - acc: 0.9983\n",
      "Epoch 111/150\n",
      "579/579 [==============================] - 0s 135us/step - loss: 0.0031 - acc: 0.9983\n",
      "Epoch 112/150\n",
      "579/579 [==============================] - 0s 111us/step - loss: 0.0033 - acc: 0.9983\n",
      "Epoch 113/150\n",
      "579/579 [==============================] - 0s 107us/step - loss: 0.0035 - acc: 0.9983\n",
      "Epoch 114/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 115/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0020 - acc: 0.9983\n",
      "Epoch 116/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0029 - acc: 0.9983\n",
      "Epoch 117/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0031 - acc: 0.9983\n",
      "Epoch 118/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0035 - acc: 0.9983\n",
      "Epoch 119/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0027 - acc: 0.9983\n",
      "Epoch 120/150\n",
      "579/579 [==============================] - 0s 81us/step - loss: 0.0049 - acc: 0.9965\n",
      "Epoch 121/150\n",
      "579/579 [==============================] - 0s 139us/step - loss: 0.0039 - acc: 0.9965\n",
      "Epoch 122/150\n",
      "579/579 [==============================] - ETA: 0s - loss: 0.0013 - acc: 1.0000    - 0s 113us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 123/150\n",
      "579/579 [==============================] - 0s 113us/step - loss: 0.0033 - acc: 0.9983\n",
      "Epoch 124/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0041 - acc: 0.9983\n",
      "Epoch 125/150\n",
      "579/579 [==============================] - 0s 117us/step - loss: 0.0069 - acc: 0.9983\n",
      "Epoch 126/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0058 - acc: 0.9965\n",
      "Epoch 127/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0029 - acc: 0.9983\n",
      "Epoch 128/150\n",
      "579/579 [==============================] - 0s 105us/step - loss: 0.0033 - acc: 0.9965\n",
      "Epoch 129/150\n",
      "579/579 [==============================] - 0s 100us/step - loss: 0.0020 - acc: 0.9983\n",
      "Epoch 130/150\n",
      "579/579 [==============================] - 0s 86us/step - loss: 0.0023 - acc: 0.9983\n",
      "Epoch 131/150\n",
      "579/579 [==============================] - 0s 146us/step - loss: 0.0036 - acc: 0.9965\n",
      "Epoch 132/150\n",
      "579/579 [==============================] - 0s 110us/step - loss: 0.0018 - acc: 0.9983\n",
      "Epoch 133/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0028 - acc: 0.9983\n",
      "Epoch 134/150\n",
      "579/579 [==============================] - 0s 138us/step - loss: 0.0025 - acc: 0.9983\n",
      "Epoch 135/150\n",
      "579/579 [==============================] - 0s 114us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 136/150\n",
      "579/579 [==============================] - 0s 121us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 137/150\n",
      "579/579 [==============================] - 0s 83us/step - loss: 0.0025 - acc: 0.9983\n",
      "Epoch 138/150\n",
      "579/579 [==============================] - 0s 136us/step - loss: 0.0022 - acc: 0.9983\n",
      "Epoch 139/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0040 - acc: 0.9965\n",
      "Epoch 140/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0020 - acc: 0.9983\n",
      "Epoch 141/150\n",
      "579/579 [==============================] - 0s 109us/step - loss: 0.0021 - acc: 0.9983\n",
      "Epoch 142/150\n",
      "579/579 [==============================] - 0s 112us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 143/150\n",
      "579/579 [==============================] - 0s 119us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 144/150\n",
      "579/579 [==============================] - 0s 122us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 145/150\n",
      "579/579 [==============================] - 0s 115us/step - loss: 0.0016 - acc: 0.9983\n",
      "Epoch 146/150\n",
      "579/579 [==============================] - 0s 78us/step - loss: 0.0045 - acc: 0.9965\n",
      "Epoch 147/150\n",
      "579/579 [==============================] - 0s 149us/step - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 148/150\n",
      "579/579 [==============================] - 0s 80us/step - loss: 0.0053 - acc: 0.9983\n",
      "Epoch 149/150\n",
      "579/579 [==============================] - 0s 141us/step - loss: 0.0034 - acc: 0.9983\n",
      "Epoch 150/150\n",
      "579/579 [==============================] - 0s 88us/step - loss: 0.0235 - acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d9d8d17eb8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim=44, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(5,activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X_train_reduced, y_train, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 0s 532us/step\n",
      "\n",
      "acc: 93.81%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_reduced, y_test)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In conslusion the results for Deep neural regressor were little less effective. It performed less than polynomial features regression. But classification results were very effective. PCA defintely made the deep neural regressor and classification less effective but difference wasn't that significant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
