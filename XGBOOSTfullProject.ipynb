{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification project by Obaid Masih. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read in training data and do initial analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('exercise_03_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40000 entries, 0 to 39999\n",
      "Columns: 101 entries, x0 to y\n",
      "dtypes: float64(94), int64(1), object(6)\n",
      "memory usage: 30.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Null values & missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39204, 101)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I will remove all the missing values, null values and empty spaces \n",
    "df.replace(r'\\s+', np.nan, regex=True)\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyze which x variable are objects so they can be converted to hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['y'], dtype='object'),\n",
       " dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x42', 'x43',\n",
       "        'x44', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54',\n",
       "        'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64',\n",
       "        'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75',\n",
       "        'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85',\n",
       "        'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94', 'x95', 'x96',\n",
       "        'x97', 'x98', 'x99'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['x34', 'x35', 'x41', 'x45', 'x68', 'x93'], dtype='object')}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have 6 object variables. Check their unique values and clean data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wed' 'wednesday' 'thurday' 'thur' 'friday' 'tuesday' 'monday' 'fri']\n",
      "['wednesday' 'thursday' 'friday' 'tuesday' 'monday']\n"
     ]
    }
   ],
   "source": [
    "### check unique values of daya \n",
    "print(df['x35'].unique())\n",
    "df['x35'] = df['x35'].replace('wed','wednesday')\n",
    "df['x35'] = df['x35'].replace('thur','thursday')\n",
    "df['x35'] = df['x35'].replace('thurday','thursday')\n",
    "df['x35'] = df['x35'].replace('fri','friday')\n",
    "print(df['x35'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In Month X68 there is a value called 'Dev'. I don't know what it is but I will keep it there incase it signifies a special month or time period in month. In real life I will ask business experts on this and clean it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['July' 'Jun' 'Aug' 'sept.' 'May' 'Apr' 'Oct' 'Mar' 'Dev' 'Nov' 'Feb'\n",
      " 'January']\n"
     ]
    }
   ],
   "source": [
    "### check unique values of months \n",
    "print(df['x68'].unique()) ###  I am okay with all the values but don't understand what 'Dev' is \n",
    "df['x68'] = df['x68'].replace('Dev','Dec')\n",
    "#res\n",
    "### I don't know what Dev is but I will keep it there incase it signifies a special month or  a time period in month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honda' 'volkswagon' 'ford' 'Toyota' 'bmw' 'chrystler' 'tesla' 'nissan'\n",
      " 'mercades' 'chevrolet']\n"
     ]
    }
   ],
   "source": [
    "### check unique values cars \n",
    "print(df['x34'].unique())  ## looks good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['asia' 'america' 'euorpe']\n"
     ]
    }
   ],
   "source": [
    "### check unique values of regions \n",
    "print(df['x93'].unique())  ## looks good "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['y'], dtype='object'),\n",
       " dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x42', 'x43',\n",
       "        'x44', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54',\n",
       "        'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64',\n",
       "        'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75',\n",
       "        'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85',\n",
       "        'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94', 'x95', 'x96',\n",
       "        'x97', 'x98', 'x99'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['x34', 'x35', 'x41', 'x45', 'x68', 'x93'], dtype='object')}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     $229.47\n",
       "1      $213.9\n",
       "2    $2207.13\n",
       "Name: x41, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x41'].head(3)   ### this should be converted to numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x41'] = df['x41'].apply(lambda x: x.strip('$'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     229.47\n",
       "1      213.9\n",
       "2    2207.13\n",
       "Name: x41, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['x41'].head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x41'] = df['x41'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['y'], dtype='object'),\n",
       " dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42',\n",
       "        'x43', 'x44', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53',\n",
       "        'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63',\n",
       "        'x64', 'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74',\n",
       "        'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84',\n",
       "        'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94', 'x95',\n",
       "        'x96', 'x97', 'x98', 'x99'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['x34', 'x35', 'x45', 'x68', 'x93'], dtype='object')}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    July\n",
       "1     Jun\n",
       "2     Aug\n",
       "Name: x68, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Change x45 to numeric instead of string ( object type)\n",
    "df['x68'].head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x45'] = df['x45'].apply(lambda x: x.strip('%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x45'] = df['x45'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('int64'): Index(['y'], dtype='object'),\n",
       " dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42',\n",
       "        'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52',\n",
       "        'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62',\n",
       "        'x63', 'x64', 'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73',\n",
       "        'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83',\n",
       "        'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94',\n",
       "        'x95', 'x96', 'x97', 'x98', 'x99'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['x34', 'x35', 'x68', 'x93'], dtype='object')}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n",
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Data is cleaned and now we can create hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convery these categorical variables to hot vectors ## first lets convert x34 which has cars\n",
    "result=pd.get_dummies(df['x34'],columns='cars',prefix='cars')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x34',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39204, 110)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convery these categorical variables to hot vectors ## first lets convert x35 which has days\n",
    "result=pd.get_dummies(df['x35'],columns='days',prefix='days')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x35',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39204, 114)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convery these categorical variables to hot vectors ## first lets convert x68 which has days\n",
    "result=pd.get_dummies(df['x68'],columns='months',prefix='months')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x68',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39204, 125)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### convery these categorical variables to hot vectors ## first lets convert x93 which has regions\n",
    "result=pd.get_dummies(df['x93'],columns='regions',prefix='regions')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x93',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39204, 127)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('uint8'): Index(['cars_Honda', 'cars_Toyota', 'cars_bmw', 'cars_chevrolet',\n",
       "        'cars_chrystler', 'cars_ford', 'cars_mercades', 'cars_nissan',\n",
       "        'cars_tesla', 'cars_volkswagon', 'days_friday', 'days_monday',\n",
       "        'days_thursday', 'days_tuesday', 'days_wednesday', 'months_Apr',\n",
       "        'months_Aug', 'months_Dec', 'months_Feb', 'months_January',\n",
       "        'months_July', 'months_Jun', 'months_Mar', 'months_May', 'months_Nov',\n",
       "        'months_Oct', 'months_sept.', 'regions_america', 'regions_asia',\n",
       "        'regions_euorpe'],\n",
       "       dtype='object'),\n",
       " dtype('int64'): Index(['y'], dtype='object'),\n",
       " dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x41', 'x42',\n",
       "        'x43', 'x44', 'x45', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52',\n",
       "        'x53', 'x54', 'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62',\n",
       "        'x63', 'x64', 'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73',\n",
       "        'x74', 'x75', 'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83',\n",
       "        'x84', 'x85', 'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94',\n",
       "        'x95', 'x96', 'x97', 'x98', 'x99'],\n",
       "       dtype='object')}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define y & X "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df['y']\n",
    "X = df.drop(['y'],axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split data into training and test. Then scale it accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "x_train_org,x_test_org,y_train,y_test=train_test_split(X,y,random_state=0)  ## org stands for the very original\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(x_train_org)  ### you can fit and transform together \n",
    "X_test = scaler.transform(x_test_org)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST. Instead of random forest we will use the wrong label values and run trees on it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "classifier = XGBClassifier(max_depth=6,learning_rate=0.01)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error for xgboost 0.9957147229874502\n",
      "testing error  for xgboost 0.9642893582287522\n"
     ]
    }
   ],
   "source": [
    "print(\"training accuracy for xgboost\", classifier.score(X_train,y_train) )\n",
    "print(\"testing accuracy  for xgboost\" ,classifier.score(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with penalty l1. Using default solver "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8882086861884841, 0.891779750365609, 0.8912355882052851, 0.8914056388803864, 0.8914056388803864]\n",
      "[0.8866442199775533, 0.8908274665850423, 0.8918477706356495, 0.8915416794204672, 0.8918477706356495]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clist = [0.01,0.1,1,10,100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "\n",
    "for c in clist:\n",
    "    log_l1 = LogisticRegression(penalty='l1', C=c)\n",
    "    log_l1.fit(X_train,y_train)\n",
    "    train_score_list.append(log_l1.score(X_train,y_train))\n",
    "    test_score_list.append(log_l1.score(X_test,y_test))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression with penalty l2 and solver = 'lbfgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8909635071251233, 0.8915416794204672, 0.8913716287453661, 0.8914056388803864, 0.8913036084753256]\n",
      "[0.8912355882052851, 0.8906234057749209, 0.8914396490154066, 0.891643709825528, 0.8919498010407101]\n"
     ]
    }
   ],
   "source": [
    "clist = [0.01,0.1,1,10,100]\n",
    "train_score_list = []\n",
    "test_score_list = []\n",
    "\n",
    "\n",
    "for c in clist:\n",
    "    log_l2 = LogisticRegression(penalty='l2', C=c, solver='lbfgs')\n",
    "    log_l2.fit(X_train,y_train)\n",
    "    train_score_list.append(log_l2.score(X_train,y_train))\n",
    "    test_score_list.append(log_l2.score(X_test,y_test))\n",
    "\n",
    "print(train_score_list)\n",
    "print(test_score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree ( simple) with max depth =6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is  0.8460701288984117\n",
      "testing score is 0.830833588409346\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier(random_state=0,max_depth=6)\n",
    "\n",
    "dtree.fit(X_train,y_train)\n",
    "\n",
    "print(\"training score is \",dtree.score(X_train,y_train))\n",
    "print(\"testing score is\", dtree.score(X_test,y_test))\n",
    "## lets ensemble this with random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use desicion tree ensemble - Random forest with 50 decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is  0.9999659898649798\n",
      "rfc accuracy 0.8682787470666259\n"
     ]
    }
   ],
   "source": [
    "### lets do random forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50)\n",
    "rfc.fit(X_train,y_train)\n",
    "print(\"training score is \",rfc.score(X_train,y_train))\n",
    "print(\"rfc accuracy\",rfc.score(X_test,y_test))\n",
    "\n",
    "### I tried with number of estimators and 50 is good decision trees is good "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Simple Linear SVC with no kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score is  0.8918137605006292\n",
      "testing score is 0.8907254361799817\n",
      " coefficents are  (1, 126)\n",
      "intercepts are (1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svm = LinearSVC().fit(X_train,y_train)\n",
    "print(\"training score is \",linear_svm.score(X_train,y_train))\n",
    "print(\"testing score is\", linear_svm.score(X_test,y_test))\n",
    "\n",
    "print(\" coefficents are \",linear_svm.coef_.shape)\n",
    "print(\"intercepts are\",linear_svm.intercept_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble model with hard voting on 3 different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my voting 0.8917457402305887\n"
     ]
    }
   ],
   "source": [
    "###  lets do a voting of 3 models that are giving good results \n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "myVotingObject = VotingClassifier(estimators=[('SVC Linear',linear_svm),('dec tree',dtree),('logistic',log_l2) ],voting='hard')\n",
    "myVotingObject.fit(X_train,y_train)\n",
    "print(\"my voting\",myVotingObject.score(X_test,y_test))\n",
    "\n",
    "\n",
    "###  didnot break that 89% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am choosing Linear SVC model  with no Kernel & Logisitic regression with Penalty l2 and C=100. Lets bring the test data in, clean it and get it ready "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('exercise_03_test.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9796, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I will remove all the missing values, null values and empty spaces \n",
    "df.replace(r'\\s+', np.nan, regex=True)\n",
    "df.replace('', np.nan, inplace=True)\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{dtype('float64'): Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9', 'x10',\n",
       "        'x11', 'x12', 'x13', 'x14', 'x15', 'x16', 'x17', 'x18', 'x19', 'x20',\n",
       "        'x21', 'x22', 'x23', 'x24', 'x25', 'x26', 'x27', 'x28', 'x29', 'x30',\n",
       "        'x31', 'x32', 'x33', 'x36', 'x37', 'x38', 'x39', 'x40', 'x42', 'x43',\n",
       "        'x44', 'x46', 'x47', 'x48', 'x49', 'x50', 'x51', 'x52', 'x53', 'x54',\n",
       "        'x55', 'x56', 'x57', 'x58', 'x59', 'x60', 'x61', 'x62', 'x63', 'x64',\n",
       "        'x65', 'x66', 'x67', 'x69', 'x70', 'x71', 'x72', 'x73', 'x74', 'x75',\n",
       "        'x76', 'x77', 'x78', 'x79', 'x80', 'x81', 'x82', 'x83', 'x84', 'x85',\n",
       "        'x86', 'x87', 'x88', 'x89', 'x90', 'x91', 'x92', 'x94', 'x95', 'x96',\n",
       "        'x97', 'x98', 'x99'],\n",
       "       dtype='object'),\n",
       " dtype('O'): Index(['x34', 'x35', 'x41', 'x45', 'x68', 'x93'], dtype='object')}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = df.columns.to_series().groupby(df.dtypes).groups\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['x35'] = df['x35'].replace('wed','wednesday')\n",
    "df['x35'] = df['x35'].replace('thur','thursday')\n",
    "df['x35'] = df['x35'].replace('thurday','thursday')\n",
    "df['x35'] = df['x35'].replace('fri','friday')\n",
    "\n",
    "df['x41'] = df['x41'].apply(lambda x: x.strip('$'))\n",
    "\n",
    "df['x41'] = df['x41'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df['x45'] = df['x45'].apply(lambda x: x.strip('%'))\n",
    "df['x45'] = df['x45'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get your hot vectors ready \n",
    "\n",
    "result=pd.get_dummies(df['x34'],columns='cars',prefix='cars')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x34',axis=1)\n",
    "\n",
    "result=pd.get_dummies(df['x35'],columns='days',prefix='days')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x35',axis=1)\n",
    "\n",
    "result=pd.get_dummies(df['x68'],columns='months',prefix='months')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x68',axis=1)\n",
    "\n",
    "result=pd.get_dummies(df['x93'],columns='regions',prefix='regions')\n",
    "df=pd.concat([df, result], axis=1)\n",
    "df = df.drop('x93',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\obaid\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "## scale our data before predict \n",
    "\n",
    "X_test = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y1']= linear_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['y1_decisionScore'] = linear_svm.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y1_prob']= 1/(1+np.exp(-df['y1_decisionScore']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### now with our second model \n",
    "df['y2']= log_l2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y2_decisionScore'] = log_l2.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['y2_prob']= 1/(1+np.exp(-df['y2_decisionScore']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lets create the result file.  File result1.csv will have LINEAR SVC  And file result2.csv will have Logistice regression Penalty l2 , C=100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
       "       ...\n",
       "       'months_sept.', 'regions_america', 'regions_asia', 'regions_euorpe',\n",
       "       'y1', 'y1_decisionScore', 'y1_prob', 'y2', 'y2_decisionScore',\n",
       "       'y2_prob'],\n",
       "      dtype='object', length=132)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
       "       ...\n",
       "       'months_May', 'months_Nov', 'months_Oct', 'months_sept.',\n",
       "       'regions_america', 'regions_asia', 'regions_euorpe', 'y1',\n",
       "       'y1_decisionScore', 'y1_prob'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### File with Linear SVC \n",
    "result1 = df.drop(['y2','y2_decisionScore','y2_prob'],axis=1)\n",
    "result1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'x9',\n",
       "       ...\n",
       "       'months_May', 'months_Nov', 'months_Oct', 'months_sept.',\n",
       "       'regions_america', 'regions_asia', 'regions_euorpe', 'y2',\n",
       "       'y2_decisionScore', 'y2_prob'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### File with Logistic regression penalty l2 , C = 100\n",
    "result2 = df.drop(['y1','y1_decisionScore','y1_prob'],axis=1)\n",
    "result2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = result2.to_csv (r'result2.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = result1.to_csv (r'result1.csv', index = None, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
